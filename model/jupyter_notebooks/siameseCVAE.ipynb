{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siameseCVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christopher-hsu/latent-map-planning/blob/master/model/jupyter_notebooks/siameseCVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrjsCpUNmdpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shared by all\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# For DataLoader\n",
        "from PIL import Image\n",
        "import numbers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGua5QHwbAVe",
        "colab_type": "code",
        "outputId": "82179d87-3dd9-4e06-a0b8-840257bcd49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUC4mk_Lm-wA",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Code: `CarlaDataset.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYae0Zdym6iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CarlaDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        # xcxc I'm assuming that the images live in _out.\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.df = self._get_dataframe()\n",
        "        self.df_as_mat = self.df.values\n",
        "    \n",
        "    def __len__(self):\n",
        "        num_rows, _ = self.df_as_mat.shape\n",
        "        return num_rows\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Generate one sample of data.\n",
        "        '''\n",
        "        # We're gonna do some hardcore hard-coding here.\n",
        "        # First, extract our control inputs\n",
        "        row = self.df_as_mat[idx, :]\n",
        "        # xcxc We're... We're not exactly doing anything with our control inputs. For now.\n",
        "        # We lop off the final value in -1 because of our dataframe- we \n",
        "        # interpret the indicator value of whether it's stationary or not \n",
        "        # as a boolean, and python interprets it as a number.\n",
        "        control_inputs = np.array(\n",
        "            [x for x in row if isinstance(x, numbers.Number)][:-1])\n",
        "        is_stationary = row[-1]\n",
        "        \n",
        "        curr_images = self._get_image_tensor_for_row(row[0], is_stationary)\n",
        "        # Get the next row\n",
        "        next_delta = 4 # xcxc This is a hardcoded parameter from Klayton's data.\n",
        "        next_input_id = int(row[0]) + next_delta\n",
        "        num_rows_next = np.sum(self.df['input_num'] == str(next_input_id))\n",
        "        if num_rows_next == 0:\n",
        "            # No next: treat it as if we're stationary\n",
        "            return (curr_images, curr_images, np.zeros(len(control_inputs)))\n",
        "        elif is_stationary == True:\n",
        "            # If it's stationary, then simply return our current images\n",
        "            return (curr_images, curr_images, np.zeros(len(control_inputs)))\n",
        "        else:\n",
        "            next_images = self._get_image_tensor_for_row(\n",
        "                str(next_input_id), is_stationary)\n",
        "            return (curr_images, next_images, control_inputs)\n",
        "    \n",
        "    def _get_image_tensor_for_row(self, row_id, is_stationary):\n",
        "        '''\n",
        "        Inputs:\n",
        "            row_id: String that represents the input_num\n",
        "        Outputs:\n",
        "            A (2 x H x W x 4) 4D matrix of the two images.\n",
        "        '''\n",
        "        # The row_id should be the input_num. Should also be a string.\n",
        "        which_row = (self.df['input_num'] == row_id)\n",
        "        where_stationary = (self.df['is_stationary'] == is_stationary)\n",
        "        row = self.df[which_row & where_stationary]\n",
        "        n_res, _ = row.shape\n",
        "        if n_res > 1:\n",
        "            # xcxc I'm assuming there's only one row per row_id.\n",
        "            # This may or may not be a strictly held invariant.\n",
        "            print(\"XCXC: THERE ARE MORE THAN 1 ROW FOR A ROW_ID\")\n",
        "        row = row.values[0]\n",
        "        images = []\n",
        "        for ele in row:\n",
        "            if str(ele).split('.')[-1] == 'png':\n",
        "                full_name = os.path.join(self.data_dir, '_out', ele)\n",
        "                np_arr = np.asarray(Image.open(full_name))\n",
        "                np_arr = self._rearrange_axes_image(np_arr)\n",
        "                # Apply transform on each image independently.\n",
        "                if self.transform:\n",
        "                    np_arr = self.transform(np_arr)\n",
        "                images.append(np_arr)\n",
        "        images = np.array(images)\n",
        "        return images\n",
        "    \n",
        "    def _rearrange_axes_image(self, img):\n",
        "        H,W,_ = img.shape\n",
        "        new_img = np.zeros((3,H,W))\n",
        "        for i in range(3):\n",
        "            new_img[i,:,:] = img[:,:,i]\n",
        "        return new_img\n",
        "\n",
        "    def _get_dataframe(self):\n",
        "        control_input_df = self._get_control_input_df()\n",
        "        filename_df = self._get_image_path_df()\n",
        "        df = control_input_df.merge(right=filename_df,\n",
        "                                    left_on='input_num',\n",
        "                                    right_on='index')\n",
        "        # Then, we add a column to our dataframe saying whether it's stationary or not\n",
        "        num_rows, _ = df.shape\n",
        "        df['is_stationary'] = np.zeros((num_rows), dtype=bool)\n",
        "        # Then make a copy and set is_stationary to true...\n",
        "        df_copy = df.copy()\n",
        "        df_copy['is_stationary'] = np.ones((num_rows), dtype=bool)\n",
        "        # then stack and return\n",
        "        final_df = pd.concat([df, df_copy])\n",
        "        return final_df\n",
        "\n",
        "    def _get_control_input_df(self):\n",
        "        # xcxc I'm also assuming that our columns in control_input stay static like so.\n",
        "        control_input_df = pd.read_csv(os.path.join(self.data_dir, 'control_input.txt'),\n",
        "                               names=['input_num', 'ctr1', 'ctr2'])\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('str')\n",
        "        return control_input_df\n",
        "    \n",
        "    def _get_image_path_df(self):\n",
        "        # A little cryptic, but it just gets the list of all filenames\n",
        "        all_files_in_out = [x[2] for x in os.walk(os.path.join(self.data_dir, '_out'))][0]\n",
        "        # Then filter out by getting only the png files. We can remove this step if need be.\n",
        "        all_files_in_out = [img_name for img_name in all_files_in_out if img_name.split('.')[1] == 'png']\n",
        "\n",
        "        # We can then make a map with our data...\n",
        "        filename_groupings = {}\n",
        "        for fn in all_files_in_out:\n",
        "            fn_number = str(int(fn.split('_')[0]))\n",
        "            if fn_number not in filename_groupings:\n",
        "                filename_groupings[fn_number] = []\n",
        "            filename_groupings[fn_number].append(fn)\n",
        "            \n",
        "        # Then make a dataframe from this dictionary\n",
        "        filename_df = pd.DataFrame.from_dict(\n",
        "            filename_groupings, orient='index').reset_index()\n",
        "        filename_df = filename_df.dropna(subset=[0,1]) # Drop if any of our images is None.\n",
        "#         filename_df = filename_df[filename_df['index'].astype('int') < 494] # Drop all the ones that are after 494\n",
        "        return filename_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHtv9Wq9nIL3",
        "colab_type": "text"
      },
      "source": [
        "### Model: `siameseCVAE.py` (xcxc To be changed later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1p1k2hTecrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtC1hjdInHm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseCVAE(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\td = 0.4\n",
        "\t\tself.z_size = 64\n",
        "\t\tself.hidden = 1024\n",
        "\t\tself.small = 256\n",
        "\t\tch_sz = 3\n",
        "\t\tlast_conv = 2\n",
        "\t\tself.tensor = (1,last_conv,300,400)\n",
        "\t\tflat = np.prod(self.tensor)*2\n",
        "\t\tself.flat = flat\n",
        "\n",
        "\t\t# channel_in, c_out, kernel_size, stride, padding\n",
        "\t\tdef convbn(ci,co,ksz,s=1,pz=0):\t\t#ReLu nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef convout(ci,co,ksz,s=1,pz=0):\t#Sigmoid nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.Sigmoid(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef mlp(in_size,hidden):\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tnn.Linear(in_size,hidden),\n",
        "\t\t\t\tnn.ReLU())\n",
        "\n",
        "\t\t#Encoder NN\n",
        "\t\tself.encx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,16,3,1,1),\n",
        "\t\t\t\tconvbn(16,8,1,1),\n",
        "\t\t\t\tconvbn(8,last_conv,1,1))\n",
        "\t\tself.ency = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,16,3,1,1),\n",
        "\t\t\t\tconvbn(16,8,1,1),\n",
        "\t\t\t\tconvbn(8,last_conv,1,1))\n",
        "\t\tself.m1 = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(flat,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden, self.small))\n",
        "\t\tself.zmean = nn.Linear(self.small,self.z_size)\n",
        "\t\tself.zstdev = nn.Linear(self.small,self.z_size)\n",
        "\n",
        "\t\t#Decoder NN\n",
        "\t\tself.expand_z = nn.Linear(self.z_size,self.small)\n",
        "\t\tself.m2 = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.decx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,8,1,1),\n",
        "\t\t\t\tconvbn(8,16,1,1),\n",
        "\t\t\t\tconvout(16,ch_sz,1,1))\n",
        "\t\tself.decy = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,8,1,1),\n",
        "\t\t\t\tconvbn(8,16,1,1),\n",
        "\t\t\t\tconvout(16,ch_sz,1,1))\n",
        "\n",
        "\tdef encoder(self, x, y, ctrl):\n",
        "\t\th_x = torch.flatten(self.encx(x))\n",
        "\t\th_y = torch.flatten(self.ency(y))\t\n",
        "\t\t# Concatenate flat convs\n",
        "\t\th_layer = torch.cat((h_x,h_y))\n",
        "\t\th = self.m1(h_layer)\n",
        "\t\treturn h\n",
        "\n",
        "\tdef bottleneck(self, x):\n",
        "\t\tz_mean = self.zmean(x)\n",
        "\t\tz_stdev = self.zstdev(x)\n",
        "\t\t#reparam to get z latent sample\n",
        "\t\tstd = torch.exp(0.5*z_stdev)\n",
        "\t\teps = torch.randn_like(std)\n",
        "\t\tz = z_mean + eps*std\n",
        "\t\treturn z, z_mean, z_stdev\n",
        "\n",
        "\tdef decoder(self, z):\n",
        "\t\t#check the nonlinearities of this layer\n",
        "\t\th = self.expand_z(z)\n",
        "\t\th_layer = self.m2(h)\n",
        "\t\t#Split in 2\n",
        "\t\th_x = h_layer[:int(self.flat/2)]\n",
        "\t\th_y = h_layer[int(self.flat/2):]\n",
        "\t\t#make sure to reshape data correctly and decode\n",
        "\t\tx = self.decx(torch.reshape(h_x,(self.tensor)))\n",
        "\t\ty = self.decy(torch.reshape(h_x,(self.tensor)))\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef forward(self, x, y, ctrl):\n",
        "\t\th = self.encoder(x, y, ctrl)\n",
        "\t\tz, z_mean, z_stdev = self.bottleneck(h)\n",
        "\t\tx_hat, y_hat = self.decoder(z)\n",
        "\t\treturn x_hat, y_hat, z, z_mean, z_stdev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eXmqdvaJMV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ELBO_loss(xhat, x, yhat, y, mu, logvar):\n",
        "    mseloss = nn.MSELoss()\n",
        "    MSE_X = mseloss(xhat, x)\n",
        "    MSE_Y = mseloss(yhat, y)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return MSE_X+MSE_Y+KLD, MSE_X, MSE_Y, KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhgG8l-L32i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = DataLoader(CarlaDataset(\"/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/data\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXWrqmrnfEl",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `run_script.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POg-yHcNm7xU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2c97c2a-02db-417c-9263-4ea07a5c5cfb"
      },
      "source": [
        "def train(net, optimizer, criterion, epochs):\n",
        "    model = net\n",
        "    total_step = 0\n",
        "    losses = []\n",
        "    kl_loss = []\n",
        "    mseX_loss = []\n",
        "    mseY_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        kl_running = 0.0\n",
        "        mseX_running = 0.0\n",
        "        mseY_running = 0.0\n",
        "        for i, X in enumerate(dl):\n",
        "            left_image_t = X[0][:, 0, :, :, :] # left/right images of t\n",
        "            right_image_t = X[0][:, 1, :, :, :] # left/right images of t\n",
        "\n",
        "            # img2 = X[1] # left/right of t+1 # xcxc do the same indexing above to get l/r of t+1\n",
        "            ctrl_inputs = X[2]\n",
        "            left_image_t = (left_image_t/255).float()\n",
        "            right_image_t = (right_image_t/255).float()\n",
        "\n",
        "            left_image_t.to(device)\n",
        "            right_image_t.to(device)\n",
        "            ctrl_inputs.to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_stdev = model.forward(left_image_t,right_image_t,ctrl_inputs)\n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,left_image_t, yhat, right_image_t, z_mean, z_stdev)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            total_step += 1\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += ctrl_inputs.size(0)\n",
        "\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseX_loss.append(mseX_running/total)  \n",
        "\n",
        "    plt.plot(losses, label='ELBO')\n",
        "    plt.plot(kl_loss, label='KL')\n",
        "    plt.plot(mseX_loss, label='MSE')\n",
        "    plt.plot(mseX_loss, label='MSE')\n",
        "    plt.title('Train loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "#Run from here\n",
        "model = siameseCVAE()\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "train(model, optimizer, criterion, epochs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [1/1], Loss: 3.9223\n",
            "Epoch [1/2], Step [2/2], Loss: 4.4490\n",
            "Epoch [1/2], Step [3/3], Loss: 5.0342\n",
            "Epoch [1/2], Step [4/4], Loss: 4.7705\n",
            "Epoch [1/2], Step [5/5], Loss: 5.4678\n",
            "Epoch [1/2], Step [6/6], Loss: 5.3439\n",
            "Epoch [1/2], Step [7/7], Loss: 4.8427\n",
            "Epoch [1/2], Step [8/8], Loss: 4.9228\n",
            "Epoch [1/2], Step [9/9], Loss: 4.5526\n",
            "Epoch [1/2], Step [10/10], Loss: 5.2087\n",
            "Epoch [1/2], Step [11/11], Loss: 4.8646\n",
            "Epoch [1/2], Step [12/12], Loss: 4.7910\n",
            "Epoch [1/2], Step [13/13], Loss: 4.5768\n",
            "Epoch [1/2], Step [14/14], Loss: 4.1649\n",
            "Epoch [1/2], Step [15/15], Loss: 4.5925\n",
            "Epoch [1/2], Step [16/16], Loss: 4.5613\n",
            "Epoch [1/2], Step [17/17], Loss: 4.6825\n",
            "Epoch [1/2], Step [18/18], Loss: 4.1259\n",
            "Epoch [1/2], Step [19/19], Loss: 4.7032\n",
            "Epoch [1/2], Step [20/20], Loss: 4.9877\n",
            "Epoch [1/2], Step [21/21], Loss: 4.8643\n",
            "Epoch [1/2], Step [22/22], Loss: 4.3565\n",
            "Epoch [1/2], Step [23/23], Loss: 4.5651\n",
            "Epoch [1/2], Step [24/24], Loss: 5.3751\n",
            "Epoch [1/2], Step [25/25], Loss: 4.1086\n",
            "Epoch [1/2], Step [26/26], Loss: 4.4764\n",
            "Epoch [1/2], Step [27/27], Loss: 4.7175\n",
            "Epoch [1/2], Step [28/28], Loss: 5.3355\n",
            "Epoch [1/2], Step [29/29], Loss: 4.3888\n",
            "Epoch [1/2], Step [30/30], Loss: 3.9932\n",
            "Epoch [1/2], Step [31/31], Loss: 3.8429\n",
            "Epoch [1/2], Step [32/32], Loss: 5.1224\n",
            "Epoch [1/2], Step [33/33], Loss: 5.0604\n",
            "Epoch [1/2], Step [34/34], Loss: 4.1566\n",
            "Epoch [1/2], Step [35/35], Loss: 4.4684\n",
            "Epoch [1/2], Step [36/36], Loss: 4.1141\n",
            "Epoch [1/2], Step [37/37], Loss: 4.9561\n",
            "Epoch [1/2], Step [38/38], Loss: 5.1543\n",
            "Epoch [1/2], Step [39/39], Loss: 4.4452\n",
            "Epoch [1/2], Step [40/40], Loss: 4.8175\n",
            "Epoch [1/2], Step [41/41], Loss: 4.2941\n",
            "Epoch [1/2], Step [42/42], Loss: 5.1046\n",
            "Epoch [1/2], Step [43/43], Loss: 5.3963\n",
            "Epoch [1/2], Step [44/44], Loss: 4.4905\n",
            "Epoch [1/2], Step [45/45], Loss: 4.7046\n",
            "Epoch [1/2], Step [46/46], Loss: 4.8942\n",
            "Epoch [1/2], Step [47/47], Loss: 4.4852\n",
            "Epoch [1/2], Step [48/48], Loss: 4.6520\n",
            "Epoch [1/2], Step [49/49], Loss: 4.0625\n",
            "Epoch [1/2], Step [50/50], Loss: 4.8447\n",
            "Epoch [1/2], Step [51/51], Loss: 4.1054\n",
            "Epoch [1/2], Step [52/52], Loss: 4.0236\n",
            "Epoch [1/2], Step [53/53], Loss: 4.5981\n",
            "Epoch [1/2], Step [54/54], Loss: 4.3656\n",
            "Epoch [1/2], Step [55/55], Loss: 4.9935\n",
            "Epoch [1/2], Step [56/56], Loss: 4.4771\n",
            "Epoch [1/2], Step [57/57], Loss: 4.1747\n",
            "Epoch [1/2], Step [58/58], Loss: 4.2081\n",
            "Epoch [1/2], Step [59/59], Loss: 4.7700\n",
            "Epoch [1/2], Step [60/60], Loss: 5.0190\n",
            "Epoch [1/2], Step [61/61], Loss: 4.0475\n",
            "Epoch [1/2], Step [62/62], Loss: 4.5958\n",
            "Epoch [1/2], Step [63/63], Loss: 4.6274\n",
            "Epoch [1/2], Step [64/64], Loss: 4.4639\n",
            "Epoch [1/2], Step [65/65], Loss: 4.4990\n",
            "Epoch [1/2], Step [66/66], Loss: 3.9880\n",
            "Epoch [1/2], Step [67/67], Loss: 4.3378\n",
            "Epoch [1/2], Step [68/68], Loss: 5.2614\n",
            "Epoch [1/2], Step [69/69], Loss: 4.3243\n",
            "Epoch [1/2], Step [70/70], Loss: 4.5609\n",
            "Epoch [1/2], Step [71/71], Loss: 4.3375\n",
            "Epoch [1/2], Step [72/72], Loss: 5.1441\n",
            "Epoch [1/2], Step [73/73], Loss: 4.9893\n",
            "Epoch [1/2], Step [74/74], Loss: 4.3245\n",
            "Epoch [1/2], Step [75/75], Loss: 4.0026\n",
            "Epoch [1/2], Step [76/76], Loss: 4.8227\n",
            "Epoch [1/2], Step [77/77], Loss: 5.4923\n",
            "Epoch [1/2], Step [78/78], Loss: 4.4128\n",
            "Epoch [1/2], Step [79/79], Loss: 4.5487\n",
            "Epoch [1/2], Step [80/80], Loss: 4.6455\n",
            "Epoch [1/2], Step [81/81], Loss: 4.2532\n",
            "Epoch [1/2], Step [82/82], Loss: 4.6568\n",
            "Epoch [1/2], Step [83/83], Loss: 4.3984\n",
            "Epoch [1/2], Step [84/84], Loss: 5.1836\n",
            "Epoch [1/2], Step [85/85], Loss: 4.0199\n",
            "Epoch [1/2], Step [86/86], Loss: 3.9954\n",
            "Epoch [1/2], Step [87/87], Loss: 4.6697\n",
            "Epoch [1/2], Step [88/88], Loss: 5.4606\n",
            "Epoch [1/2], Step [89/89], Loss: 4.3720\n",
            "Epoch [1/2], Step [90/90], Loss: 4.6052\n",
            "Epoch [1/2], Step [91/91], Loss: 4.0598\n",
            "Epoch [1/2], Step [92/92], Loss: 4.8971\n",
            "Epoch [1/2], Step [93/93], Loss: 3.8986\n",
            "Epoch [1/2], Step [94/94], Loss: 4.5731\n",
            "Epoch [1/2], Step [95/95], Loss: 4.2576\n",
            "Epoch [1/2], Step [96/96], Loss: 4.6236\n",
            "Epoch [1/2], Step [97/97], Loss: 4.4432\n",
            "Epoch [1/2], Step [98/98], Loss: 4.2230\n",
            "Epoch [1/2], Step [99/99], Loss: 4.3310\n",
            "Epoch [1/2], Step [100/100], Loss: 5.3554\n",
            "Epoch [1/2], Step [101/101], Loss: 4.5133\n",
            "Epoch [1/2], Step [102/102], Loss: 5.1346\n",
            "Epoch [1/2], Step [103/103], Loss: 4.3760\n",
            "Epoch [1/2], Step [104/104], Loss: 4.3837\n",
            "Epoch [1/2], Step [105/105], Loss: 4.7697\n",
            "Epoch [1/2], Step [106/106], Loss: 5.2653\n",
            "Epoch [1/2], Step [107/107], Loss: 4.6027\n",
            "Epoch [1/2], Step [108/108], Loss: 4.6434\n",
            "Epoch [1/2], Step [109/109], Loss: 4.3938\n",
            "Epoch [1/2], Step [110/110], Loss: 4.1241\n",
            "Epoch [1/2], Step [111/111], Loss: 4.6062\n",
            "Epoch [1/2], Step [112/112], Loss: 4.3588\n",
            "Epoch [1/2], Step [113/113], Loss: 4.6891\n",
            "Epoch [1/2], Step [114/114], Loss: 4.7090\n",
            "Epoch [1/2], Step [115/115], Loss: 5.0481\n",
            "Epoch [1/2], Step [116/116], Loss: 4.8977\n",
            "Epoch [1/2], Step [117/117], Loss: 3.8632\n",
            "Epoch [1/2], Step [118/118], Loss: 6.5130\n",
            "Epoch [1/2], Step [119/119], Loss: 4.5443\n",
            "Epoch [1/2], Step [120/120], Loss: 5.1154\n",
            "Epoch [1/2], Step [121/121], Loss: 4.2385\n",
            "Epoch [1/2], Step [122/122], Loss: 4.2965\n",
            "Epoch [1/2], Step [123/123], Loss: 4.5063\n",
            "Epoch [1/2], Step [124/124], Loss: 4.5121\n",
            "Epoch [1/2], Step [125/125], Loss: 4.3220\n",
            "Epoch [1/2], Step [126/126], Loss: 4.2625\n",
            "Epoch [1/2], Step [127/127], Loss: 3.7681\n",
            "Epoch [1/2], Step [128/128], Loss: 5.8481\n",
            "Epoch [1/2], Step [129/129], Loss: 4.5008\n",
            "Epoch [1/2], Step [130/130], Loss: 4.2817\n",
            "Epoch [1/2], Step [131/131], Loss: 5.1271\n",
            "Epoch [1/2], Step [132/132], Loss: 4.0141\n",
            "Epoch [1/2], Step [133/133], Loss: 4.8439\n",
            "Epoch [1/2], Step [134/134], Loss: 4.3621\n",
            "Epoch [1/2], Step [135/135], Loss: 4.8894\n",
            "Epoch [1/2], Step [136/136], Loss: 3.9134\n",
            "Epoch [1/2], Step [137/137], Loss: 4.5052\n",
            "Epoch [1/2], Step [138/138], Loss: 5.0596\n",
            "Epoch [1/2], Step [139/139], Loss: 4.7968\n",
            "Epoch [1/2], Step [140/140], Loss: 4.2407\n",
            "Epoch [1/2], Step [141/141], Loss: 4.6802\n",
            "Epoch [1/2], Step [142/142], Loss: 5.0574\n",
            "Epoch [1/2], Step [143/143], Loss: 4.7693\n",
            "Epoch [1/2], Step [144/144], Loss: 4.0121\n",
            "Epoch [1/2], Step [145/145], Loss: 4.0024\n",
            "Epoch [1/2], Step [146/146], Loss: 4.4350\n",
            "Epoch [1/2], Step [147/147], Loss: 4.7986\n",
            "Epoch [1/2], Step [148/148], Loss: 4.7421\n",
            "Epoch [1/2], Step [149/149], Loss: 4.2863\n",
            "Epoch [1/2], Step [150/150], Loss: 3.8977\n",
            "Epoch [1/2], Step [151/151], Loss: 4.3332\n",
            "Epoch [1/2], Step [152/152], Loss: 4.5559\n",
            "Epoch [1/2], Step [153/153], Loss: 5.1139\n",
            "Epoch [1/2], Step [154/154], Loss: 4.9296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7b40fc1d050d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-7b40fc1d050d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mctrl_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mxhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_stdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_image_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_image_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mctrl_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_image_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_image_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_stdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-13977981b428>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, ctrl)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_stdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_stdev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-13977981b428>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m#make sure to reshape data correctly and decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V-qxTudMCqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}