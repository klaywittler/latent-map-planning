{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "velocityModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "widjDd5ekWdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shared by all\n",
        "import os, pickle\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "# For DataLoader\n",
        "from PIL import Image\n",
        "import numbers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HDddlmbkgjz",
        "colab_type": "code",
        "outputId": "ef3ae17c-e447-466c-f14b-60995ed6f1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/' )#, force_remount=True)\n",
        "\n",
        "base = '/content/drive/My Drive/School/Fall 2019/ESE 546/project/'\n",
        "os.makedirs(base+'checkpoints', exist_ok=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvl8kypVkseG",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Code: `VelocityPredicitionCaralDataset.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4JBoptCkmWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from PIL import Image\n",
        "import numbers\n",
        "import glob\n",
        "\n",
        "class VelocityPredictionCarlaDataSet(Dataset):\n",
        "    def __init__(self, data_dir, goal_images={}, delta=100, load_as_grayscale=False, transform=None):\n",
        "        # xcxc I'm assuming that the images live in _out.\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.goal_images = goal_images\n",
        "        self.delta = delta\n",
        "        self.load_as_grayscale = load_as_grayscale\n",
        "        self.df = self._get_dataframe()\n",
        "    \n",
        "    def __len__(self):\n",
        "        num_rows, _ = self.df.shape\n",
        "        return num_rows\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Generate one sample of data.\n",
        "        '''\n",
        "        row = self.df.iloc[idx]\n",
        "        ctr1 = float(row['ctr1'])\n",
        "        ctr2 = float(row['ctr2'])\n",
        "        control_inputs = np.array([ctr1, ctr2])\n",
        "        src_img = self._load_image_and_maybe_apply_transform(row['src'])\n",
        "        tgt_img = self._load_image_and_maybe_apply_transform(row['tgt'])\n",
        "        return (src_img, tgt_img, control_inputs)\n",
        "\n",
        "    def _load_image_and_maybe_apply_transform(self, filename):\n",
        "        '''\n",
        "        Inputs:\n",
        "            image_loc: The location of the image we want to load\n",
        "        Outputs:\n",
        "            Either the grayscale image, a RGB image with the axes flopped, or \n",
        "            the RGB image with some series of transformations applied. \n",
        "            All are converted to numpy arrays before yeeting them out.\n",
        "        '''\n",
        "        # I've been writing too much haskell\n",
        "        image_loc = os.path.join(self.data_dir, '_out', filename)\n",
        "        pil_img = Image.open(image_loc)\n",
        "        if self.load_as_grayscale:\n",
        "            pil_img = pil_img.convert('L')\n",
        "        \n",
        "        if self.transform:\n",
        "            transform_result = self.transform(pil_img)\n",
        "            return np.asarray(transform_result[:3, :, :])\n",
        "        else:\n",
        "            if self.load_as_grayscale:\n",
        "                return np.array(pil_img)\n",
        "            else:\n",
        "                return self._rearrange_axes_image(np.array(pil_img))\n",
        "\n",
        "    def _rearrange_axes_image(self, img):\n",
        "        H,W,_ = img.shape\n",
        "        new_img = np.zeros((3,H,W))\n",
        "        for i in range(3):\n",
        "            new_img[i,:,:] = img[:,:,i]\n",
        "        return new_img\n",
        "\n",
        "    def _get_dataframe(self):\n",
        "        control_input_df = self._get_control_input_df()\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('int') \n",
        "        filename_df = self._get_image_path_df()\n",
        "        pairwise_df = self._get_pairwise_df(filename_df)\n",
        "        pairwise_df['index'] = pairwise_df['index'].astype('int')\n",
        "        df = control_input_df.merge(right=pairwise_df,\n",
        "                                    left_on=['input_num', 'trajectory'],\n",
        "                                    right_on=['index', 'trajectory'])\n",
        "        stationary_mask = (df['src'] == df['tgt'])\n",
        "        ctr1_col = df['ctr1'].copy()\n",
        "        ctr2_col = df['ctr2'].copy()\n",
        "        ctr1_col[stationary_mask] = 0\n",
        "        ctr2_col[stationary_mask] = 0\n",
        "        df['ctr1'] = ctr1_col\n",
        "        df['ctr2'] = ctr2_col\n",
        "        df = df[['trajectory', 'index', 'ctr1', 'ctr2', 'src', 'tgt']]\n",
        "        return df.drop_duplicates()\n",
        "\n",
        "    def _get_control_input_df(self):\n",
        "        # xcxc I'm also assuming that our columns in control_input stay static like so.\n",
        "        control_input_df = pd.read_csv(os.path.join(self.data_dir, 'control_input.txt'),\n",
        "                               names=['trajectory', 'input_num', 'ctr1', 'ctr2'])\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('str')\n",
        "        control_input_df['trajectory'] =control_input_df['trajectory'].astype('str')\n",
        "        return control_input_df\n",
        "    \n",
        "    def _get_image_path_df(self):\n",
        "        '''\n",
        "        Different from the OG CarlaDS.\n",
        "        This returns a dataframe of the \n",
        "        '''\n",
        "        all_files_in_out = self._get_image_files_in_directory()\n",
        "        # We can then make a map with our data...\n",
        "        filename_groupings = {}\n",
        "        for fn in all_files_in_out:\n",
        "            # Apologies for the hardcoding\n",
        "            fn_number = str(int(fn.split('_')[0]))\n",
        "            trajectory_number = str(int(fn.split('_')[2].split('.')[0]))\n",
        "            if (fn_number, trajectory_number) not in filename_groupings:\n",
        "                filename_groupings[(fn_number, trajectory_number)] = []\n",
        "            filename_groupings[(fn_number, trajectory_number)].append(fn)\n",
        "            \n",
        "        # Then make a dataframe from this dictionary\n",
        "        filename_df = self._get_initial_filename_dataframe(filename_groupings)\n",
        "        return filename_df\n",
        "    \n",
        "    def _get_initial_filename_dataframe(self, filename_groupings):\n",
        "        '''\n",
        "        Given the filename groupings from the above, create a dataframe\n",
        "        of the schema [trajectory, index, image1, image2]\n",
        "        '''\n",
        "        filename_df = pd.DataFrame(columns=['trajectory', 'index', 'src'])\n",
        "        for k,v in filename_groupings.items():\n",
        "            (index, traj) = k\n",
        "            img1 = None\n",
        "            if len(v) == 1:\n",
        "                img1 = v[0]\n",
        "            filename_df = filename_df.append({\n",
        "                'trajectory': traj,\n",
        "                'index': index,\n",
        "                'src': img1\n",
        "            }, ignore_index=True)\n",
        "        filename_df['trajectory'] = filename_df['trajectory'].astype('str')\n",
        "        filename_df['index'] = filename_df['index'].astype('int')\n",
        "        filename_df = filename_df.dropna(subset=['src']) # Drop if any of our images is None.\n",
        "        return filename_df\n",
        "    \n",
        "    def _get_pairwise_df(self, filename_df):\n",
        "        pairwise_df = pd.DataFrame(columns=['trajectory', 'index', 'src', 'tgt'])\n",
        "        trajectory_map = self._construct_trajectory_map(filename_df)\n",
        "        for trajectory, goal_fn in trajectory_map.items():\n",
        "            fn_subset_df = filename_df[filename_df['trajectory']==trajectory]\n",
        "            pairwise_df = self._get_pairwise_combinations_for_goal(\n",
        "                goal_fn, fn_subset_df, pairwise_df)\n",
        "        pairwise_df['trajectory'] = pairwise_df['trajectory'].astype('str')\n",
        "        pairwise_df['index'] = pairwise_df['index'].astype('str')\n",
        "        return pairwise_df\n",
        "    \n",
        "    def _construct_trajectory_map(self, filename_df):\n",
        "        '''\n",
        "        Constructs a map such that\n",
        "        {trajectory: goal}\n",
        "        So then it's just a matter of iterating through this map.\n",
        "        '''\n",
        "        if len(self.goal_images) > 0:\n",
        "            return self.goal_images\n",
        "        trajectories = filename_df['trajectory'].unique().tolist()\n",
        "        def helper(traj):\n",
        "            return filename_df[filename_df['trajectory']==traj]['src'].max()\n",
        "            \n",
        "        goal_filenames = map(lambda t: helper(t), trajectories)\n",
        "        goal_filenames = list(goal_filenames)\n",
        "        return {trajectories[i]: goal_filenames[i] for i in range(len(trajectories))}\n",
        "    \n",
        "    def _get_pairwise_combinations_for_goal(self, goal_image, filename_df, pairwise_df):\n",
        "        '''\n",
        "        With filename_df, we construct the ('index', 'src', 'tgt' here), constructed by \n",
        "        '''\n",
        "        num_rows, _ = filename_df.shape\n",
        "        tgt_index = int(goal_image.split('_')[0]) # Get which # image we want to go up to\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            # Get data from our current row\n",
        "            ith_row = filename_df.iloc[i]\n",
        "            index = int(ith_row['index'])\n",
        "            # Get all the potential target images\n",
        "            src_filename = ith_row['src']\n",
        "            timestep = 1 # images increment by 1\n",
        "            indices = list(np.arange(index, tgt_index, self.delta * timestep)) # Hardcoding in 4 because images increment by 4\n",
        "            if self.delta != 1:\n",
        "                indices.append(index + timestep) # And to get t+1 as well.\n",
        "            tgt_rows = filename_df[filename_df['index'].astype('int').isin(indices)] # Get all the target rows\n",
        "            # Then loop through our filenames and pair them together and append them to our df\n",
        "            for tgt_filename in tgt_rows['src']:\n",
        "                pairwise_df = pairwise_df.append({\n",
        "                    'trajectory': ith_row['trajectory'],\n",
        "                    'index': index,\n",
        "                    'src': src_filename,\n",
        "                    'tgt': tgt_filename\n",
        "                }, ignore_index=True)\n",
        "        return pairwise_df\n",
        "    \n",
        "    def _get_image_files_in_directory(self, end='png'):\n",
        "        '''\n",
        "        Retrieves all the filenames in the data directory with some end extension.\n",
        "        Currently, end is png.\n",
        "        '''\n",
        "        full_data = glob.glob(os.path.join(self.data_dir, '_out', '**.' + end))\n",
        "        abbrev_data = [x.split('/')[-1] for x in full_data]\n",
        "        return abbrev_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciYP-EuwPgDA",
        "colab_type": "text"
      },
      "source": [
        "### Model: `velocityNN.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6mPImzQRFK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class velocityNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64,256),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.vel = nn.Linear(256,6)\n",
        "        self.steer = nn.Linear(256,11)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.fc(x)\n",
        "        vel = self.vel(h)\n",
        "        steer = self.steer(h)\n",
        "        # vel = F.softmax(vel, dim=6)\n",
        "        # vel = F.softmax(steer, dim=11)\n",
        "        return vel.unsqueeze(0) , steer.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr_pa3iVlHJy",
        "colab_type": "text"
      },
      "source": [
        "### Model: `siameseCVAE.py` (xcxc To be changed later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMICuhAklF3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseCVAE(nn.Module):\n",
        "\tdef __init__(self,batch=4):\n",
        "\t\tsuper().__init__()\n",
        "\t\td = 0.4\n",
        "\t\tself.z_size = 64\n",
        "\t\tself.small = 256\n",
        "\t\tself.hidden = 1024\n",
        "\t\tch_sz = 1\n",
        "\t\tc1 = 64\n",
        "\t\tc2 = 16\n",
        "\t\tlast_conv = 4\n",
        "\t\tself.tensor = (batch,last_conv,150,200)\n",
        "\t\tflat = np.prod(self.tensor)\n",
        "\t\tflat2 = flat*2\n",
        "\n",
        "\t\t# channel_in, c_out, kernel_size, stride, padding\n",
        "\t\tdef convbn(ci,co,ksz,s=1,pz=0):\t\t#ReLu nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef convout(ci,co,ksz,s=1,pz=0):\t#Sigmoid nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.Sigmoid(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef mlp(in_size,hidden):\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tnn.Linear(in_size,hidden),\n",
        "\t\t\t\tnn.ReLU())\n",
        "\n",
        "\t\t#Encoder NN\n",
        "\t\tself.encx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.ency = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.m1 = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(flat2,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden, self.small))\n",
        "\t\tself.zmean = nn.Linear(self.small,self.z_size)\n",
        "\t\tself.zlogvar = nn.Linear(self.small,self.z_size)\n",
        "\n",
        "\t\t#Decoder NN\n",
        "\t\tself.expand_z = nn.Linear(self.z_size,self.small)\n",
        "\t\tself.mx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.my = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.decx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\t\tself.decy = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\n",
        "\tdef encoder(self, x, y):\n",
        "\t\t# Flatten enc output\n",
        "\t\th_x = self.encx(x).view(-1)\n",
        "\t\th_y = self.ency(y).view(-1)\n",
        "\t\t# Concatenate flat convs\n",
        "\t\th_layer = torch.cat((h_x,h_y))\n",
        "\t\th = self.m1(h_layer)\n",
        "\t\treturn h\n",
        "\n",
        "\tdef bottleneck(self, x):\n",
        "\t\tz_mean = self.zmean(x)\n",
        "\t\tz_logvar = self.zlogvar(x)\n",
        "\t\t#reparam to get z latent sample\n",
        "\t\tstd = torch.exp(0.5*z_logvar)\n",
        "\t\teps = torch.randn_like(std)\n",
        "\t\tz = z_mean + eps*std\n",
        "\t\treturn z, z_mean, z_logvar\n",
        "\n",
        "\tdef decoder(self, z):\n",
        "\t\t#check the nonlinearities of this layer\n",
        "\t\th = self.expand_z(z)\n",
        "\t\t#exand z to each decoder head\n",
        "\t\th_x = self.mx(h)\n",
        "\t\th_y = self.my(h)\n",
        "\t\t#make sure to reshape data correctly and decode\n",
        "\t\tx = self.decx(h_x.view(self.tensor))\n",
        "\t\ty = self.decy(h_x.view(self.tensor))\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef forward(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\tx_hat, y_hat = self.decoder(z)\n",
        "\t\treturn x_hat, y_hat, z, z_mean, z_logvar\n",
        "\n",
        "\tdef encode_get_z(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\treturn z, z_mean, z_logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moTnnTc5lkBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _rearrange_channel_last(img, color = False):\n",
        "    _,_,H,W = img.shape\n",
        "    if color == True:\n",
        "        new_img = np.zeros((H,W,3))\n",
        "        for i in range(3):\n",
        "            new_img[:,:,i] = img[0,i,:,:]\n",
        "    else:\n",
        "        new_img = np.zeros((H,W))\n",
        "        new_img[:,:] = img[0,0,:,:]\n",
        "    return new_img\n",
        "\n",
        "def ELBO_loss(xhat, x, yhat, y, mu, logvar):\n",
        "    mseloss = nn.MSELoss(reduction='sum')\n",
        "    MSE_X = mseloss(xhat, x)\n",
        "    MSE_Y = mseloss(yhat, y)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return MSE_X+MSE_Y+KLD, MSE_X, MSE_Y, KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Uv8T5DlwcP",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `train_velModel.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCDXdR_CJABE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(net, optimizer, criterion, epochs, dataloader, exp_name):\n",
        "    model = net.to(device)\n",
        "    total_step = len(dataloader)\n",
        "    overall_step = 0\n",
        "    losses, kl_loss, mseX_loss, mseY_loss = [], [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0 \n",
        "        running_loss, kl_running, mseX_running, mseY_running = 0.0, 0.0, 0.0, 0.0\n",
        "        for i, X in enumerate(dataloader):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_logvar = model.forward(t0,tk)\n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,t0, yhat, tk, z_mean, z_logvar)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += X[2].size(0)\n",
        "\n",
        "            if (i+1) % 10 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "            \n",
        "            if i == 25:\n",
        "                break\n",
        "        \n",
        "        if (epoch+1) % 10 == 0:\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseY_loss.append(mseY_running/total)  \n",
        "    \n",
        "    ells = {'elbo':losses,\n",
        "            'kl':kl_loss,\n",
        "            'mseX':mseX_loss,\n",
        "            'mseY':mseY_loss}\n",
        "\n",
        "    with open(base+'logs/'+exp_name+'_losses.pickle', 'wb') as f:\n",
        "        pickle.dump(ells, f)\n",
        "\n",
        "    return ells       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphtXd6dU9t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testVAE(net, criterion, dataloader):\n",
        "    t0_list, tk_list = [], []\n",
        "    recon_t0_list, recon_tk_list = [], []\n",
        "    for i, X in enumerate(dataloader):\n",
        "        model.eval()\n",
        "        t0 = X[0].float().to(device)\n",
        "        tk = X[1].float().to(device)\n",
        "        u = X[2].float().to(device)\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(t0,tk)\n",
        "\n",
        "        t0_ = t0.cpu().squeeze().numpy()\n",
        "        tk_ = tk.cpu().squeeze().numpy()\n",
        "        xhat_ = xhat.cpu().detach().squeeze().numpy()\n",
        "        yhat_ = yhat.cpu().detach().squeeze().numpy()\n",
        "\n",
        "        t0_list.append(t0_)\n",
        "        tk_list.append(tk_)\n",
        "        recon_t0_list.append(xhat_)\n",
        "        recon_tk_list.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "\n",
        "    t0_list = np.asarray(t0_list)\n",
        "    tk_list = np.asarray(tk_list)\n",
        "    recon_t0_list = np.asarray(recon_t0_list)\n",
        "    recon_tk_list = np.asarray(recon_tk_list)\n",
        "\n",
        "    result = {'t0':t0_list, 'tk':tk_list, 'recon_t0':recon_t0_list, 'recon_tk':recon_tk_list}\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX0w5UbalWu1",
        "colab_type": "code",
        "outputId": "be90cfc8-7ed6-42dc-a090-2da8e8b2dbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize((150,200)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "batch = 1\n",
        "path = base + \"project_data/synced_single_camera/\"\n",
        "\n",
        "print(os.listdir(base))\n",
        "\n",
        "dl = DataLoader(VelocityPredictionCarlaDataSet(path, load_as_grayscale=True, transform=transform), batch_size=batch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['project_data', 'ESE546 Roadmap.gdoc', 'siameseCVAE.ipynb', 'checkpoints', 'logs', 'velocityModel.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu7RKuq1MZCe",
        "colab_type": "code",
        "outputId": "8b60afe3-7d39-47e9-96eb-1116fb8443eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Run from here\n",
        "exp_name = 'siamese_single_test'\n",
        "model = siameseCVAE(batch=batch)\n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "ells = trainVAE(model, optimizer, criterion, epochs, dl, exp_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [10/2398], Loss: 51365.7305\n",
            "Epoch [1/1], Step [20/2398], Loss: 49199.1133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuqriY8OLSgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(ells['elbo'], label='ELBO')\n",
        "plt.plot(ells['kl'], label='KL')\n",
        "plt.plot(ells['mseX'], label='MSE')\n",
        "plt.plot(ells['mseY'], label='MSE')\n",
        "plt.title('Train loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFak1rLWHg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = testVAE(model, criterion, dl):\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(221)\n",
        "plt.imshow(result['t0'][0], cmap = 'gray')\n",
        "plt.subplot(222)\n",
        "plt.imshow(result['tk'][0], cmap = 'gray')\n",
        "plt.subplot(223)\n",
        "plt.imshow(result['recon_t0'][0], cmap = 'gray')\n",
        "plt.subplot(224)\n",
        "plt.imshow(result['recon_tk'][0], cmap = 'gray')\n",
        "plt.figure()\n",
        "plt.subplot(221)\n",
        "plt.imshow(result['t0'][30], cmap = 'gray')\n",
        "plt.subplot(222)\n",
        "plt.imshow(result['tk'][30], cmap = 'gray')\n",
        "plt.subplot(223)\n",
        "plt.imshow(result['recon_t0'][30], cmap = 'gray')\n",
        "plt.subplot(224)\n",
        "plt.imshow(result['recon_tk'][30], cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V71As9S3hUaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input2classification(control, lb, ub, num_class):\n",
        "    interval_list = torch.linspace(lb,ub,num_class).to(device)\n",
        "    val = abs(interval_list-control.unsqueeze(1))\n",
        "    idx = torch.argmin(val, axis=1)\n",
        "    label = torch.zeros((control.shape[0],interval_list.shape[0])).to(device)\n",
        "    \n",
        "    i = np.arange(0, control.shape[0])\n",
        "    i = torch.from_numpy(i).to(device)\n",
        "\n",
        "    label[i,idx] = 1\n",
        "    return idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwnPAnLQl8yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVel(netVAE, netVel, optimizer, criterion, epochs, dataloader, exp_name):\n",
        "    modelVAE = netVAE.to(device)\n",
        "    modelVel = netVel.to(device)\n",
        "    total_step = len(dataloader)\n",
        "    overall_step = 0\n",
        "    accuracy, loss_list = [], []\n",
        "    for epoch in range(epochs):\n",
        "        modelVel.train()\n",
        "        modelVAE.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        total_loss = 0\n",
        "        for i, X in enumerate(dataloader):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "            u = X[2].float().to(device)\n",
        "\n",
        "            label_vel = input2classification(u[:,1],0,50,6)\n",
        "            label_steer = input2classification(u[:,0],-1,1,11)\n",
        "\n",
        "            #Forward Pass\n",
        "            xhat, yhat, z, z_mean, z_stdev = modelVAE.forward(t0,tk)\n",
        "            vel, steer = modelVel.forward(z)\n",
        "\n",
        "            loss = criterion(vel, label_vel) + criterion(steer, label_steer) \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(vel.data, 1)\n",
        "            total += label_vel.size(0)\n",
        "            correct += (predicted == label_vel).sum().item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            acc = 100*(predicted == label_vel).sum().item()/label_vel.size(0)\n",
        "            overall_step += 1\n",
        "\n",
        "            if (i+1) % 10 == 0:\n",
        "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {}'.format(epoch+1, epochs, overall_step, total_step*epochs, loss.item(), acc))\n",
        "\n",
        "            if i == 40:\n",
        "                break\n",
        "            \n",
        "        if (epoch+1) % 10 == 0:\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(modelVel.state_dict(), chpt_path)\n",
        "\n",
        "        accuracy.append(correct/total)\n",
        "        loss_list.append(total_loss/total)\n",
        "\n",
        "    ells = {'accuracy':accuracy,'loss':loss_list}\n",
        "\n",
        "    return ells"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw5poYhyH0gx",
        "colab_type": "code",
        "outputId": "1d8a75f1-903c-42df-dcae-67e7adbe63d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#Run from here\n",
        "modelVAE = siameseCVAE(batch=batch)\n",
        "checkpoint = torch.load(base+'checkpoints/siamese_chpt.pt')\n",
        "modelVAE.load_state_dict(checkpoint) \n",
        "\n",
        "\n",
        "exp_name = 'velocity_single_test'\n",
        "modelVel = velocityNN()\n",
        "\n",
        "epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelVel.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "ells = trainVel(modelVAE, modelVel, optimizer, criterion, epochs, dl, exp_name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [10/23980], Loss: 0.1073, Accuracy: 100.0\n",
            "Epoch [1/10], Step [20/23980], Loss: 0.0015, Accuracy: 100.0\n",
            "Epoch [1/10], Step [30/23980], Loss: 0.0009, Accuracy: 100.0\n",
            "Epoch [1/10], Step [40/23980], Loss: 0.0338, Accuracy: 100.0\n",
            "Epoch [2/10], Step [51/23980], Loss: 0.8008, Accuracy: 0.0\n",
            "Epoch [2/10], Step [61/23980], Loss: 0.2168, Accuracy: 100.0\n",
            "Epoch [2/10], Step [71/23980], Loss: 0.0003, Accuracy: 100.0\n",
            "Epoch [2/10], Step [81/23980], Loss: 0.0486, Accuracy: 100.0\n",
            "Epoch [3/10], Step [92/23980], Loss: 0.1551, Accuracy: 100.0\n",
            "Epoch [3/10], Step [102/23980], Loss: 0.0084, Accuracy: 100.0\n",
            "Epoch [3/10], Step [112/23980], Loss: 0.0010, Accuracy: 100.0\n",
            "Epoch [3/10], Step [122/23980], Loss: 0.0556, Accuracy: 100.0\n",
            "Epoch [4/10], Step [133/23980], Loss: 0.9165, Accuracy: 0.0\n",
            "Epoch [4/10], Step [143/23980], Loss: 0.0451, Accuracy: 100.0\n",
            "Epoch [4/10], Step [153/23980], Loss: 0.0229, Accuracy: 100.0\n",
            "Epoch [4/10], Step [163/23980], Loss: 0.0701, Accuracy: 100.0\n",
            "Epoch [5/10], Step [174/23980], Loss: 0.6552, Accuracy: 100.0\n",
            "Epoch [5/10], Step [184/23980], Loss: 0.1053, Accuracy: 100.0\n",
            "Epoch [5/10], Step [194/23980], Loss: 0.0324, Accuracy: 100.0\n",
            "Epoch [5/10], Step [204/23980], Loss: 0.2400, Accuracy: 100.0\n",
            "Epoch [6/10], Step [215/23980], Loss: 0.3830, Accuracy: 100.0\n",
            "Epoch [6/10], Step [225/23980], Loss: 0.2611, Accuracy: 100.0\n",
            "Epoch [6/10], Step [235/23980], Loss: 0.0919, Accuracy: 100.0\n",
            "Epoch [6/10], Step [245/23980], Loss: 0.1091, Accuracy: 100.0\n",
            "Epoch [7/10], Step [256/23980], Loss: 0.2621, Accuracy: 100.0\n",
            "Epoch [7/10], Step [266/23980], Loss: 0.2368, Accuracy: 100.0\n",
            "Epoch [7/10], Step [276/23980], Loss: 0.0495, Accuracy: 100.0\n",
            "Epoch [7/10], Step [286/23980], Loss: 0.3307, Accuracy: 100.0\n",
            "Epoch [8/10], Step [297/23980], Loss: 0.3236, Accuracy: 100.0\n",
            "Epoch [8/10], Step [307/23980], Loss: 0.0456, Accuracy: 100.0\n",
            "Epoch [8/10], Step [317/23980], Loss: 0.0474, Accuracy: 100.0\n",
            "Epoch [8/10], Step [327/23980], Loss: 0.1955, Accuracy: 100.0\n",
            "Epoch [9/10], Step [338/23980], Loss: 0.4226, Accuracy: 100.0\n",
            "Epoch [9/10], Step [348/23980], Loss: 0.1723, Accuracy: 100.0\n",
            "Epoch [9/10], Step [358/23980], Loss: 0.0273, Accuracy: 100.0\n",
            "Epoch [9/10], Step [368/23980], Loss: 0.0373, Accuracy: 100.0\n",
            "Epoch [10/10], Step [379/23980], Loss: 0.3223, Accuracy: 100.0\n",
            "Epoch [10/10], Step [389/23980], Loss: 0.2439, Accuracy: 100.0\n",
            "Epoch [10/10], Step [399/23980], Loss: 0.0668, Accuracy: 100.0\n",
            "Epoch [10/10], Step [409/23980], Loss: 0.1798, Accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIwLxZThH3qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "b2e4cfdc-3999-4537-cb5f-d5a205b5e9bc"
      },
      "source": [
        "plt.plot(ells['accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(ells['loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETCnIpARCTMqQhERMKcikBEJMz9f/9VGLlXzj1DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvNy0SbLQg62",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `run_script.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q5CPAt0ll8X",
        "colab_type": "code",
        "outputId": "4f207675-a962-4b18-8326-d142bc15919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "def train(net, optimizer, criterion, epochs, batch, exp_name):\n",
        "    model = net.to(device)\n",
        "    total_step = len(dl)\n",
        "    overall_step = 0\n",
        "    losses = []\n",
        "    kl_loss = []\n",
        "    mseX_loss = []\n",
        "    mseY_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        kl_running = 0.0\n",
        "        mseX_running = 0.0\n",
        "        mseY_running = 0.0\n",
        "\n",
        "        for i, X in enumerate(dl):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_logvar = model.forward(t0,tk)\n",
        "            \n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,t0, yhat, tk, z_mean, z_logvar)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += batch\n",
        "\n",
        "            overall_step += 1\n",
        "\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, overall_step, total_step, loss.item()))\n",
        "            if i == 25:\n",
        "                break\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseY_loss.append(mseY_running/total)  \n",
        "    \n",
        "    ells = {'elbo':losses,\n",
        "            'kl':kl_loss,\n",
        "            'mseX':mseX_loss,\n",
        "            'mseY':mseY_loss}\n",
        "\n",
        "    with open(base+'logs/'+exp_name+'_losses.pickle', 'wb') as f:\n",
        "        pickle.dump(ells, f)\n",
        "\n",
        "    left = []\n",
        "    right = []\n",
        "    recon_left = []\n",
        "    recon_right = []\n",
        "    for i, X in enumerate(dl):\n",
        "        model.eval()\n",
        "        t0 = X[0].float().to(device)\n",
        "        tk = X[1].float().to(device)\n",
        "        u = X[2].float().to(device)\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(t0,tk)\n",
        "\n",
        "        left_ = t0.cpu().squeeze().numpy()\n",
        "        right_ = tk.cpu().squeeze().numpy()\n",
        "        xhat_ = xhat.cpu().detach().squeeze().numpy()\n",
        "        yhat_ = yhat.cpu().detach().squeeze().numpy()\n",
        "\n",
        "        left.append(left_)\n",
        "        right.append(right_)\n",
        "        recon_left.append(xhat_)\n",
        "        recon_right.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "    left = np.asarray(left)\n",
        "    right = np.asarray(right)\n",
        "    recon_left = np.asarray(recon_left)\n",
        "    recon_right = np.asarray(recon_right)\n",
        "\n",
        "    plt.plot(losses, label='ELBO')\n",
        "    plt.plot(kl_loss, label='KL')\n",
        "    plt.plot(mseX_loss, label='MSE')\n",
        "    plt.plot(mseY_loss, label='MSE')\n",
        "    plt.title('Train loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[0], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[0], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[0], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[0], cmap = 'gray')\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[30], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[30], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[30], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[30], cmap = 'gray')\n",
        "\n",
        "\n",
        "#Run from here\n",
        "exp_name = 'siamese_single_test'\n",
        "model = siameseCVAE(batch=batch)\n",
        "# checkpoint = torch.load('/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/checkpoints/siamese_chpt.pt')\n",
        "# model.load_state_dict(checkpoint) \n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "train(model, optimizer, criterion, epochs, batch, exp_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [1/2398], Loss: 68553.3359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6ede766535af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-6ede766535af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, criterion, epochs, batch, exp_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 938.00 MiB (GPU 0; 15.90 GiB total capacity; 13.88 GiB already allocated; 845.88 MiB free; 507.41 MiB cached)"
          ]
        }
      ]
    }
  ]
}