{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "velocityModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "widjDd5ekWdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shared by all\n",
        "import os, pickle\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "# For DataLoader\n",
        "from PIL import Image\n",
        "import numbers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HDddlmbkgjz",
        "colab_type": "code",
        "outputId": "a5af2e5e-ba66-49bb-c1bb-a06c697c2be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/' )#, force_remount=True)\n",
        "\n",
        "base = '/content/drive/My Drive/School/Fall 2019/ESE 546/project/'\n",
        "os.makedirs(base+'checkpoints', exist_ok=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvl8kypVkseG",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Code: `VelocityPredicitionCaralDataset.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4JBoptCkmWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from PIL import Image\n",
        "import numbers\n",
        "import glob\n",
        "\n",
        "class VelocityPredictionCarlaDataSet(Dataset):\n",
        "    def __init__(self, data_dir, goal_images={}, delta=100, load_as_grayscale=False, transform=None):\n",
        "        # xcxc I'm assuming that the images live in _out.\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.goal_images = goal_images\n",
        "        self.delta = delta\n",
        "        self.load_as_grayscale = load_as_grayscale\n",
        "        self.df = self._get_dataframe()\n",
        "    \n",
        "    def __len__(self):\n",
        "        num_rows, _ = self.df.shape\n",
        "        return num_rows\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Generate one sample of data.\n",
        "        '''\n",
        "        row = self.df.iloc[idx]\n",
        "        ctr1 = float(row['ctr1'])\n",
        "        ctr2 = float(row['ctr2'])\n",
        "        control_inputs = np.array([ctr1, ctr2])\n",
        "        src_img = self._load_image_and_maybe_apply_transform(row['src'])\n",
        "        tgt_img = self._load_image_and_maybe_apply_transform(row['tgt'])\n",
        "        return (src_img, tgt_img, control_inputs)\n",
        "\n",
        "    def _load_image_and_maybe_apply_transform(self, filename):\n",
        "        '''\n",
        "        Inputs:\n",
        "            image_loc: The location of the image we want to load\n",
        "        Outputs:\n",
        "            Either the grayscale image, a RGB image with the axes flopped, or \n",
        "            the RGB image with some series of transformations applied. \n",
        "            All are converted to numpy arrays before yeeting them out.\n",
        "        '''\n",
        "        # I've been writing too much haskell\n",
        "        image_loc = os.path.join(self.data_dir, '_out', filename)\n",
        "        pil_img = Image.open(image_loc)\n",
        "        if self.load_as_grayscale:\n",
        "            pil_img = pil_img.convert('L')\n",
        "        \n",
        "        if self.transform:\n",
        "            transform_result = self.transform(pil_img)\n",
        "            return np.asarray(transform_result[:3, :, :])\n",
        "        else:\n",
        "            if self.load_as_grayscale:\n",
        "                return np.array(pil_img)\n",
        "            else:\n",
        "                return self._rearrange_axes_image(np.array(pil_img))\n",
        "\n",
        "    def _rearrange_axes_image(self, img):\n",
        "        H,W,_ = img.shape\n",
        "        new_img = np.zeros((3,H,W))\n",
        "        for i in range(3):\n",
        "            new_img[i,:,:] = img[:,:,i]\n",
        "        return new_img\n",
        "\n",
        "    def _get_dataframe(self):\n",
        "        control_input_df = self._get_control_input_df()\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('int') \n",
        "        filename_df = self._get_image_path_df()\n",
        "        pairwise_df = self._get_pairwise_df(filename_df)\n",
        "        pairwise_df['index'] = pairwise_df['index'].astype('int')\n",
        "        df = control_input_df.merge(right=pairwise_df,\n",
        "                                    left_on=['input_num', 'trajectory'],\n",
        "                                    right_on=['index', 'trajectory'])\n",
        "        stationary_mask = (df['src'] == df['tgt'])\n",
        "        ctr1_col = df['ctr1'].copy()\n",
        "        ctr2_col = df['ctr2'].copy()\n",
        "        ctr1_col[stationary_mask] = 0\n",
        "        ctr2_col[stationary_mask] = 0\n",
        "        df['ctr1'] = ctr1_col\n",
        "        df['ctr2'] = ctr2_col\n",
        "        df = df[['trajectory', 'index', 'ctr1', 'ctr2', 'src', 'tgt']]\n",
        "        return df.drop_duplicates()\n",
        "\n",
        "    def _get_control_input_df(self):\n",
        "        # xcxc I'm also assuming that our columns in control_input stay static like so.\n",
        "        control_input_df = pd.read_csv(os.path.join(self.data_dir, 'control_input.txt'),\n",
        "                               names=['trajectory', 'input_num', 'ctr1', 'ctr2'])\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('str')\n",
        "        control_input_df['trajectory'] =control_input_df['trajectory'].astype('str')\n",
        "        return control_input_df\n",
        "    \n",
        "    def _get_image_path_df(self):\n",
        "        '''\n",
        "        Different from the OG CarlaDS.\n",
        "        This returns a dataframe of the \n",
        "        '''\n",
        "        all_files_in_out = self._get_image_files_in_directory()\n",
        "        # We can then make a map with our data...\n",
        "        filename_groupings = {}\n",
        "        for fn in all_files_in_out:\n",
        "            # Apologies for the hardcoding\n",
        "            fn_number = str(int(fn.split('_')[0]))\n",
        "            trajectory_number = str(int(fn.split('_')[2].split('.')[0]))\n",
        "            if (fn_number, trajectory_number) not in filename_groupings:\n",
        "                filename_groupings[(fn_number, trajectory_number)] = []\n",
        "            filename_groupings[(fn_number, trajectory_number)].append(fn)\n",
        "            \n",
        "        # Then make a dataframe from this dictionary\n",
        "        filename_df = self._get_initial_filename_dataframe(filename_groupings)\n",
        "        return filename_df\n",
        "    \n",
        "    def _get_initial_filename_dataframe(self, filename_groupings):\n",
        "        '''\n",
        "        Given the filename groupings from the above, create a dataframe\n",
        "        of the schema [trajectory, index, image1, image2]\n",
        "        '''\n",
        "        filename_df = pd.DataFrame(columns=['trajectory', 'index', 'src'])\n",
        "        for k,v in filename_groupings.items():\n",
        "            (index, traj) = k\n",
        "            img1 = None\n",
        "            if len(v) == 1:\n",
        "                img1 = v[0]\n",
        "            filename_df = filename_df.append({\n",
        "                'trajectory': traj,\n",
        "                'index': index,\n",
        "                'src': img1\n",
        "            }, ignore_index=True)\n",
        "        filename_df['trajectory'] = filename_df['trajectory'].astype('str')\n",
        "        filename_df['index'] = filename_df['index'].astype('int')\n",
        "        filename_df = filename_df.dropna(subset=['src']) # Drop if any of our images is None.\n",
        "        return filename_df\n",
        "    \n",
        "    def _get_pairwise_df(self, filename_df):\n",
        "        pairwise_df = pd.DataFrame(columns=['trajectory', 'index', 'src', 'tgt'])\n",
        "        trajectory_map = self._construct_trajectory_map(filename_df)\n",
        "        for trajectory, goal_fn in trajectory_map.items():\n",
        "            fn_subset_df = filename_df[filename_df['trajectory']==trajectory]\n",
        "            pairwise_df = self._get_pairwise_combinations_for_goal(\n",
        "                goal_fn, fn_subset_df, pairwise_df)\n",
        "        pairwise_df['trajectory'] = pairwise_df['trajectory'].astype('str')\n",
        "        pairwise_df['index'] = pairwise_df['index'].astype('str')\n",
        "        return pairwise_df\n",
        "    \n",
        "    def _construct_trajectory_map(self, filename_df):\n",
        "        '''\n",
        "        Constructs a map such that\n",
        "        {trajectory: goal}\n",
        "        So then it's just a matter of iterating through this map.\n",
        "        '''\n",
        "        if len(self.goal_images) > 0:\n",
        "            return self.goal_images\n",
        "        trajectories = filename_df['trajectory'].unique().tolist()\n",
        "        def helper(traj):\n",
        "            return filename_df[filename_df['trajectory']==traj]['src'].max()\n",
        "            \n",
        "        goal_filenames = map(lambda t: helper(t), trajectories)\n",
        "        goal_filenames = list(goal_filenames)\n",
        "        return {trajectories[i]: goal_filenames[i] for i in range(len(trajectories))}\n",
        "    \n",
        "    def _get_pairwise_combinations_for_goal(self, goal_image, filename_df, pairwise_df):\n",
        "        '''\n",
        "        With filename_df, we construct the ('index', 'src', 'tgt' here), constructed by \n",
        "        '''\n",
        "        num_rows, _ = filename_df.shape\n",
        "        tgt_index = int(goal_image.split('_')[0]) # Get which # image we want to go up to\n",
        "        \n",
        "        for i in range(num_rows):\n",
        "            # Get data from our current row\n",
        "            ith_row = filename_df.iloc[i]\n",
        "            index = int(ith_row['index'])\n",
        "            # Get all the potential target images\n",
        "            src_filename = ith_row['src']\n",
        "            timestep = 1 # images increment by 1\n",
        "            indices = list(np.arange(index, tgt_index, self.delta * timestep)) # Hardcoding in 4 because images increment by 4\n",
        "            if self.delta != 1:\n",
        "                indices.append(index + timestep) # And to get t+1 as well.\n",
        "            tgt_rows = filename_df[filename_df['index'].astype('int').isin(indices)] # Get all the target rows\n",
        "            # Then loop through our filenames and pair them together and append them to our df\n",
        "            for tgt_filename in tgt_rows['src']:\n",
        "                pairwise_df = pairwise_df.append({\n",
        "                    'trajectory': ith_row['trajectory'],\n",
        "                    'index': index,\n",
        "                    'src': src_filename,\n",
        "                    'tgt': tgt_filename\n",
        "                }, ignore_index=True)\n",
        "        return pairwise_df\n",
        "    \n",
        "    def _get_image_files_in_directory(self, end='png'):\n",
        "        '''\n",
        "        Retrieves all the filenames in the data directory with some end extension.\n",
        "        Currently, end is png.\n",
        "        '''\n",
        "        full_data = glob.glob(os.path.join(self.data_dir, '_out', '**.' + end))\n",
        "        abbrev_data = [x.split('/')[-1] for x in full_data]\n",
        "        return abbrev_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciYP-EuwPgDA",
        "colab_type": "text"
      },
      "source": [
        "### Model: `velocityNN.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6mPImzQRFK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class velocityNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64,256),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.vel = nn.Linear(256,6)\n",
        "        self.steer = nn.Linear(256,11)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.fc(x)\n",
        "        vel = self.vel(h)\n",
        "        steer = self.steer(h)\n",
        "        # vel = F.softmax(vel, dim=6)\n",
        "        # vel = F.softmax(steer, dim=11)\n",
        "        return vel.unsqueeze(0) , steer.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr_pa3iVlHJy",
        "colab_type": "text"
      },
      "source": [
        "### Model: `siameseCVAE.py` (xcxc To be changed later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMICuhAklF3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseCVAE(nn.Module):\n",
        "\tdef __init__(self,batch=4):\n",
        "\t\tsuper().__init__()\n",
        "\t\td = 0.4\n",
        "\t\tself.z_size = 64\n",
        "\t\tself.small = 256\n",
        "\t\tself.hidden = 1024\n",
        "\t\tch_sz = 1\n",
        "\t\tc1 = 64\n",
        "\t\tc2 = 16\n",
        "\t\tlast_conv = 4\n",
        "\t\tself.tensor = (batch,last_conv,150,200)\n",
        "\t\tflat = np.prod(self.tensor)\n",
        "\t\tflat2 = flat*2\n",
        "\n",
        "\t\t# channel_in, c_out, kernel_size, stride, padding\n",
        "\t\tdef convbn(ci,co,ksz,s=1,pz=0):\t\t#ReLu nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef convout(ci,co,ksz,s=1,pz=0):\t#Sigmoid nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.Sigmoid(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef mlp(in_size,hidden):\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tnn.Linear(in_size,hidden),\n",
        "\t\t\t\tnn.ReLU())\n",
        "\n",
        "\t\t#Encoder NN\n",
        "\t\tself.encx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.ency = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.m1 = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(flat2,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden, self.small))\n",
        "\t\tself.zmean = nn.Linear(self.small,self.z_size)\n",
        "\t\tself.zlogvar = nn.Linear(self.small,self.z_size)\n",
        "\n",
        "\t\t#Decoder NN\n",
        "\t\tself.expand_z = nn.Linear(self.z_size,self.small)\n",
        "\t\tself.mx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.my = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.decx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\t\tself.decy = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\n",
        "\tdef encoder(self, x, y):\n",
        "\t\t# Flatten enc output\n",
        "\t\th_x = self.encx(x).view(-1)\n",
        "\t\th_y = self.ency(y).view(-1)\n",
        "\t\t# Concatenate flat convs\n",
        "\t\th_layer = torch.cat((h_x,h_y))\n",
        "\t\th = self.m1(h_layer)\n",
        "\t\treturn h\n",
        "\n",
        "\tdef bottleneck(self, x):\n",
        "\t\tz_mean = self.zmean(x)\n",
        "\t\tz_logvar = self.zlogvar(x)\n",
        "\t\t#reparam to get z latent sample\n",
        "\t\tstd = torch.exp(0.5*z_logvar)\n",
        "\t\teps = torch.randn_like(std)\n",
        "\t\tz = z_mean + eps*std\n",
        "\t\treturn z, z_mean, z_logvar\n",
        "\n",
        "\tdef decoder(self, z):\n",
        "\t\t#check the nonlinearities of this layer\n",
        "\t\th = self.expand_z(z)\n",
        "\t\t#exand z to each decoder head\n",
        "\t\th_x = self.mx(h)\n",
        "\t\th_y = self.my(h)\n",
        "\t\t#make sure to reshape data correctly and decode\n",
        "\t\tx = self.decx(h_x.view(self.tensor))\n",
        "\t\ty = self.decy(h_x.view(self.tensor))\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef forward(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\tx_hat, y_hat = self.decoder(z)\n",
        "\t\treturn x_hat, y_hat, z, z_mean, z_logvar\n",
        "\n",
        "\tdef encode_get_z(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\treturn z, z_mean, z_logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moTnnTc5lkBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _rearrange_channel_last(img, color = False):\n",
        "    _,_,H,W = img.shape\n",
        "    if color == True:\n",
        "        new_img = np.zeros((H,W,3))\n",
        "        for i in range(3):\n",
        "            new_img[:,:,i] = img[0,i,:,:]\n",
        "    else:\n",
        "        new_img = np.zeros((H,W))\n",
        "        new_img[:,:] = img[0,0,:,:]\n",
        "    return new_img\n",
        "\n",
        "def ELBO_loss(xhat, x, yhat, y, mu, logvar):\n",
        "    mseloss = nn.MSELoss(reduction='sum')\n",
        "    MSE_X = mseloss(xhat, x)\n",
        "    MSE_Y = mseloss(yhat, y)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return MSE_X+MSE_Y+KLD, MSE_X, MSE_Y, KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Uv8T5DlwcP",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `train_velModel.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCDXdR_CJABE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(net, optimizer, criterion, epochs, dataloader, exp_name):\n",
        "    model = net.to(device)\n",
        "    total_step = len(dataloader)\n",
        "    overall_step = 0\n",
        "    losses, kl_loss, mseX_loss, mseY_loss = [], [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0 \n",
        "        running_loss, kl_running, mseX_running, mseY_running = 0.0, 0.0, 0.0, 0.0\n",
        "        for i, X in enumerate(dataloader):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_logvar = model.forward(t0,tk)\n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,t0, yhat, tk, z_mean, z_logvar)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += X[2].size(0)\n",
        "\n",
        "            if (i+1) % 10 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "            \n",
        "            if i == 25:\n",
        "                break\n",
        "        \n",
        "        if (epoch+1) % 10 == 0:\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseY_loss.append(mseY_running/total)  \n",
        "    \n",
        "    ells = {'elbo':losses,\n",
        "            'kl':kl_loss,\n",
        "            'mseX':mseX_loss,\n",
        "            'mseY':mseY_loss}\n",
        "\n",
        "    with open(base+'logs/'+exp_name+'_losses.pickle', 'wb') as f:\n",
        "        pickle.dump(ells, f)\n",
        "\n",
        "    return ells       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uphtXd6dU9t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testVAE(net, criterion, dataloader):\n",
        "    t0_list, tk_list = [], []\n",
        "    recon_t0_list, recon_tk_list = [], []\n",
        "    for i, X in enumerate(dataloader):\n",
        "        model.eval()\n",
        "        t0 = X[0].float().to(device)\n",
        "        tk = X[1].float().to(device)\n",
        "        u = X[2].float().to(device)\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(t0,tk)\n",
        "\n",
        "        t0_ = t0.cpu().squeeze().numpy()\n",
        "        tk_ = tk.cpu().squeeze().numpy()\n",
        "        xhat_ = xhat.cpu().detach().squeeze().numpy()\n",
        "        yhat_ = yhat.cpu().detach().squeeze().numpy()\n",
        "\n",
        "        t0_list.append(t0_)\n",
        "        tk_list.append(tk_)\n",
        "        recon_t0_list.append(xhat_)\n",
        "        recon_tk_list.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "\n",
        "    t0_list = np.asarray(t0_list)\n",
        "    tk_list = np.asarray(tk_list)\n",
        "    recon_t0_list = np.asarray(recon_t0_list)\n",
        "    recon_tk_list = np.asarray(recon_tk_list)\n",
        "\n",
        "    result = {'t0':t0_list, 'tk':tk_list, 'recon_t0':recon_t0_list, 'recon_tk':recon_tk_list}\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX0w5UbalWu1",
        "colab_type": "code",
        "outputId": "91c5bba5-a8ac-46a0-a04d-1274bad39322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize((150,200)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "batch = 1\n",
        "path = base + \"project_data/synced_single_camera/\"\n",
        "\n",
        "print(os.listdir(base))\n",
        "\n",
        "dl = DataLoader(VelocityPredictionCarlaDataSet(path, load_as_grayscale=True, transform=transform), batch_size=batch)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['project_data', 'ESE546 Roadmap.gdoc', 'siameseCVAE.ipynb', 'checkpoints', 'logs', 'velocityModel.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu7RKuq1MZCe",
        "colab_type": "code",
        "outputId": "8b60afe3-7d39-47e9-96eb-1116fb8443eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Run from here\n",
        "exp_name = 'siamese_single_test'\n",
        "model = siameseCVAE(batch=batch)\n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "ells = trainVAE(model, optimizer, criterion, epochs, dl, exp_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [10/2398], Loss: 51365.7305\n",
            "Epoch [1/1], Step [20/2398], Loss: 49199.1133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuqriY8OLSgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(ells['elbo'], label='ELBO')\n",
        "plt.plot(ells['kl'], label='KL')\n",
        "plt.plot(ells['mseX'], label='MSE')\n",
        "plt.plot(ells['mseY'], label='MSE')\n",
        "plt.title('Train loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFak1rLWHg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = testVAE(model, criterion, dl):\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(221)\n",
        "plt.imshow(result['t0'][0], cmap = 'gray')\n",
        "plt.subplot(222)\n",
        "plt.imshow(result['tk'][0], cmap = 'gray')\n",
        "plt.subplot(223)\n",
        "plt.imshow(result['recon_t0'][0], cmap = 'gray')\n",
        "plt.subplot(224)\n",
        "plt.imshow(result['recon_tk'][0], cmap = 'gray')\n",
        "plt.figure()\n",
        "plt.subplot(221)\n",
        "plt.imshow(result['t0'][30], cmap = 'gray')\n",
        "plt.subplot(222)\n",
        "plt.imshow(result['tk'][30], cmap = 'gray')\n",
        "plt.subplot(223)\n",
        "plt.imshow(result['recon_t0'][30], cmap = 'gray')\n",
        "plt.subplot(224)\n",
        "plt.imshow(result['recon_tk'][30], cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V71As9S3hUaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input2classification(control, lb, ub, num_class):\n",
        "    interval_list = torch.linspace(lb,ub,num_class).to(device)\n",
        "    val = abs(interval_list-control.unsqueeze(1))\n",
        "    idx = torch.argmin(val, axis=1)\n",
        "    label = torch.zeros((control.shape[0],interval_list.shape[0])).to(device)\n",
        "    \n",
        "    i = np.arange(0, control.shape[0])\n",
        "    i = torch.from_numpy(i).to(device)\n",
        "\n",
        "    label[i,idx] = 1\n",
        "    return idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwnPAnLQl8yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVel(netVAE, netVel, optimizer, criterion, epochs, dataloader, exp_name):\n",
        "    modelVAE = netVAE.to(device)\n",
        "    modelVel = netVel.to(device)\n",
        "    total_step = len(dataloader)\n",
        "    overall_step = 0\n",
        "    accuracy, loss_list = [], []\n",
        "    for epoch in range(epochs):\n",
        "        modelVel.train()\n",
        "        modelVAE.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        total_loss = 0\n",
        "        for i, X in enumerate(dataloader):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "            u = X[2].float().to(device)\n",
        "\n",
        "            label_vel = input2classification(u[:,1],0,50,6)\n",
        "            label_steer = input2classification(u[:,0],-1,1,11)\n",
        "\n",
        "            #Forward Pass\n",
        "            xhat, yhat, z, z_mean, z_stdev = modelVAE.forward(t0,tk)\n",
        "            vel, steer = modelVel.forward(z)\n",
        "\n",
        "            loss = criterion(vel, label_vel) + criterion(steer, label_steer) \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(vel, 1)\n",
        "            total += label_vel.size(0)\n",
        "            correct += (predicted == label_vel).sum().item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            acc = 100*(predicted == label_vel).sum().item()/label_vel.size(0)\n",
        "            overall_step += 1\n",
        "\n",
        "            if (i+1) % 10 == 0:\n",
        "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {}'.format(epoch+1, epochs, overall_step, total_step*epochs, loss.item(), acc))\n",
        "\n",
        "            if i == 40:\n",
        "                break\n",
        "            \n",
        "        if (epoch+1) % 10 == 0:\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        accuracy.append(correct/total)\n",
        "        loss_list.append(total_loss/total)\n",
        "\n",
        "    ells = {'accuracy':accuracy,'loss':loss_list}\n",
        "\n",
        "    return ells"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw5poYhyH0gx",
        "colab_type": "code",
        "outputId": "356602ea-597c-4f11-e698-e4ef5a693df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Run from here\n",
        "modelVAE = siameseCVAE(batch=batch)\n",
        "checkpoint = torch.load(base+'checkpoints/siamese_chpt.pt')\n",
        "modelVAE.load_state_dict(checkpoint) \n",
        "\n",
        "\n",
        "exp_name = 'velocity_single_test'\n",
        "modelVel = velocityNN()\n",
        "\n",
        "epochs = 1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelVel.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "ells = trainVel(modelVAE, modelVel, optimizer, criterion, epochs, dl, exp_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [10/2398], Loss: 0.0931, Accuracy: 100.0\n",
            "Epoch [1/1], Step [20/2398], Loss: 0.0060, Accuracy: 100.0\n",
            "Epoch [1/1], Step [30/2398], Loss: 0.0002, Accuracy: 100.0\n",
            "Epoch [1/1], Step [40/2398], Loss: 0.0159, Accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIwLxZThH3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(ells['accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(ells['loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvNy0SbLQg62",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `run_script.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q5CPAt0ll8X",
        "colab_type": "code",
        "outputId": "4f207675-a962-4b18-8326-d142bc15919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "def train(net, optimizer, criterion, epochs, batch, exp_name):\n",
        "    model = net.to(device)\n",
        "    total_step = len(dl)\n",
        "    overall_step = 0\n",
        "    losses = []\n",
        "    kl_loss = []\n",
        "    mseX_loss = []\n",
        "    mseY_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        kl_running = 0.0\n",
        "        mseX_running = 0.0\n",
        "        mseY_running = 0.0\n",
        "\n",
        "        for i, X in enumerate(dl):\n",
        "            t0 = X[0].float().to(device)\n",
        "            tk = X[1].float().to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_logvar = model.forward(t0,tk)\n",
        "            \n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,t0, yhat, tk, z_mean, z_logvar)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += batch\n",
        "\n",
        "            overall_step += 1\n",
        "\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, overall_step, total_step, loss.item()))\n",
        "            if i == 25:\n",
        "                break\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "            chpt_path = base+'checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseY_loss.append(mseY_running/total)  \n",
        "    \n",
        "    ells = {'elbo':losses,\n",
        "            'kl':kl_loss,\n",
        "            'mseX':mseX_loss,\n",
        "            'mseY':mseY_loss}\n",
        "\n",
        "    with open(base+'logs/'+exp_name+'_losses.pickle', 'wb') as f:\n",
        "        pickle.dump(ells, f)\n",
        "\n",
        "    left = []\n",
        "    right = []\n",
        "    recon_left = []\n",
        "    recon_right = []\n",
        "    for i, X in enumerate(dl):\n",
        "        model.eval()\n",
        "        t0 = X[0].float().to(device)\n",
        "        tk = X[1].float().to(device)\n",
        "        u = X[2].float().to(device)\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(t0,tk)\n",
        "\n",
        "        left_ = t0.cpu().squeeze().numpy()\n",
        "        right_ = tk.cpu().squeeze().numpy()\n",
        "        xhat_ = xhat.cpu().detach().squeeze().numpy()\n",
        "        yhat_ = yhat.cpu().detach().squeeze().numpy()\n",
        "\n",
        "        left.append(left_)\n",
        "        right.append(right_)\n",
        "        recon_left.append(xhat_)\n",
        "        recon_right.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "    left = np.asarray(left)\n",
        "    right = np.asarray(right)\n",
        "    recon_left = np.asarray(recon_left)\n",
        "    recon_right = np.asarray(recon_right)\n",
        "\n",
        "    plt.plot(losses, label='ELBO')\n",
        "    plt.plot(kl_loss, label='KL')\n",
        "    plt.plot(mseX_loss, label='MSE')\n",
        "    plt.plot(mseY_loss, label='MSE')\n",
        "    plt.title('Train loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[0], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[0], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[0], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[0], cmap = 'gray')\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[30], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[30], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[30], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[30], cmap = 'gray')\n",
        "\n",
        "\n",
        "#Run from here\n",
        "exp_name = 'siamese_single_test'\n",
        "model = siameseCVAE(batch=batch)\n",
        "# checkpoint = torch.load('/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/checkpoints/siamese_chpt.pt')\n",
        "# model.load_state_dict(checkpoint) \n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "train(model, optimizer, criterion, epochs, batch, exp_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [1/2398], Loss: 68553.3359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6ede766535af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-6ede766535af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, criterion, epochs, batch, exp_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 938.00 MiB (GPU 0; 15.90 GiB total capacity; 13.88 GiB already allocated; 845.88 MiB free; 507.41 MiB cached)"
          ]
        }
      ]
    }
  ]
}