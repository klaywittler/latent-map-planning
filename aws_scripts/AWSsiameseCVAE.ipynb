{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AWSsiameseCVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrjsCpUNmdpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shared by all\n",
        "import os, pickle\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils # We should use this eventually.\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# For DataLoader\n",
        "from PIL import Image\n",
        "import numbers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUC4mk_Lm-wA",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Code: `CarlaDataset.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYae0Zdym6iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CarlaDataset(Dataset):\n",
        "    def __init__(self, data_dir, load_as_grayscale=False, transform=None):\n",
        "        # xcxc I'm assuming that the images live in _out.\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.load_as_grayscale = load_as_grayscale\n",
        "        self.df = self._get_dataframe()\n",
        "        \n",
        "    def __len__(self):\n",
        "        num_rows, _ = self.df.shape\n",
        "        return num_rows\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Generate one sample of data.\n",
        "        '''\n",
        "        # We're gonna do some hardcore hard-coding here.\n",
        "        # First, extract our control inputs\n",
        "        row = self.df.iloc[idx]\n",
        "        imgs_t0, imgs_t1 = self._get_image_tensor_for_row(row)\n",
        "        control_inputs = np.array([row['ctr1'], row['ctr2']])\n",
        "    \n",
        "        return (imgs_t0, imgs_t1, control_inputs)\n",
        "    \n",
        "    def _get_image_tensor_for_row(self, row):\n",
        "        '''\n",
        "        Inputs:\n",
        "            row_id: String that represents the input_num\n",
        "        Outputs:\n",
        "            A (2 x H x W x 4) 4D matrix of the two images.\n",
        "        '''\n",
        "        # The row_id should be the input_num. Should also be a string.\n",
        "        img_t0_filenames = [row['img1_t0'], row['img2_t0']]\n",
        "        img_t1_filenames = [row['img1_t1'], row['img2_t1']]\n",
        "        img_t0_filenames.sort()\n",
        "        img_t1_filenames.sort()\n",
        "        t0_images = []\n",
        "        for ele in img_t0_filenames:\n",
        "            full_name = os.path.join(self.data_dir, '_out', ele)\n",
        "            img_as_np_arr = self._load_image_and_maybe_apply_transform(full_name)\n",
        "            t0_images.append(img_as_np_arr)\n",
        "        t1_images = []\n",
        "        for ele in img_t1_filenames:\n",
        "            full_name = os.path.join(self.data_dir, '_out', ele)\n",
        "            img_as_np_arr = self._load_image_and_maybe_apply_transform(full_name)\n",
        "            t1_images.append(img_as_np_arr)\n",
        "        \n",
        "        t0_images = np.array(t0_images)\n",
        "        t1_images = np.array(t1_images)\n",
        "        return t0_images, t1_images\n",
        "\n",
        "    def _load_image_and_maybe_apply_transform(self, image_loc):\n",
        "        '''\n",
        "        Inputs:\n",
        "            image_loc: The location of the image we want to load\n",
        "        Outputs:\n",
        "            Either the grayscale image, a RGB image with the axes flopped, or \n",
        "            the RGB image with some series of transformations applied. \n",
        "            All are converted to numpy arrays before yeeting them out.\n",
        "        '''\n",
        "        # I've been writing too much haskell\n",
        "        pil_img = Image.open(image_loc)\n",
        "        if self.load_as_grayscale:\n",
        "            pil_img = pil_img.convert('L')\n",
        "        \n",
        "        if self.transform:\n",
        "            transform_result = self.transform(pil_img)\n",
        "            return np.asarray(transform_result[:3, :, :])\n",
        "        else:\n",
        "            if self.load_as_grayscale:\n",
        "                return np.array(pil_img)\n",
        "            else:\n",
        "                return self._rearrange_axes_image(np.array(pil_img))\n",
        "\n",
        "    def _rearrange_axes_image(self, img):\n",
        "        H,W,_ = img.shape\n",
        "        new_img = np.zeros((3,H,W))\n",
        "        for i in range(3):\n",
        "            new_img[i,:,:] = img[:,:,i]\n",
        "        return new_img\n",
        "\n",
        "    def _get_dataframe(self):\n",
        "        control_input_df = self._get_control_input_df()\n",
        "        filename_df = self._get_image_path_df()\n",
        "        df = control_input_df.merge(right=filename_df,\n",
        "                                    left_on=['trajectory','input_num'],\n",
        "                                    right_on=['trajectory', 'index'])\n",
        "        df = df.drop_duplicates() # I have no idea why we have dupes\n",
        "        \n",
        "        stationary_mask = df['img1_t0'] == df['img1_t1']\n",
        "        ctr1_col = df['ctr1'].copy()\n",
        "        ctr2_col = df['ctr2'].copy()\n",
        "        ctr1_col[stationary_mask] = 0\n",
        "        ctr2_col[stationary_mask] = 0\n",
        "        df['ctr1'] = ctr1_col\n",
        "        df['ctr2'] = ctr2_col\n",
        "        return df\n",
        "\n",
        "    def _get_control_input_df(self):\n",
        "        # xcxc I'm also assuming that our columns in control_input stay static like so.\n",
        "        control_input_df = pd.read_csv(os.path.join(self.data_dir, 'control_input.txt'),\n",
        "                               names=['trajectory', 'input_num', 'ctr1', 'ctr2'])\n",
        "        control_input_df['input_num'] = control_input_df['input_num'].astype('int')\n",
        "        control_input_df['trajectory'] = control_input_df['trajectory'].astype('str')\n",
        "        return control_input_df\n",
        "    \n",
        "    def _get_image_path_df(self):\n",
        "        filename_groupings = self._get_filename_groupings()\n",
        "        filename_df = self._get_initial_filename_dataframe(filename_groupings)\n",
        "        timestep_df = self._get_filename_dataframe_with_steps(filename_df)\n",
        "        return timestep_df\n",
        "    \n",
        "    def _get_filename_groupings(self):\n",
        "        '''\n",
        "        Reads in all the filenames, then groups them by\n",
        "        (trajectory, timestep): [images]\n",
        "        '''\n",
        "        # A little cryptic, but it just gets the list of all filenames\n",
        "        all_files_in_out = [x[2] for x in os.walk(os.path.join(self.data_dir, '_out'))][0]\n",
        "        # Then filter out by getting only the png files. We can remove this step if need be.\n",
        "        all_files_in_out = [img_name for img_name in all_files_in_out if img_name.split('.')[1] == 'png']\n",
        "\n",
        "        # We can then make a map with our data...\n",
        "        filename_groupings = {}\n",
        "        for fn in all_files_in_out:\n",
        "            # Apologies for the hardcoding\n",
        "            fn_number = str(int(fn.split('_')[0]))\n",
        "            trajectory_number = str(int(fn.split('_')[2].split('.')[0]))\n",
        "            if (fn_number, trajectory_number) not in filename_groupings:\n",
        "                filename_groupings[(fn_number, trajectory_number)] = []\n",
        "            filename_groupings[(fn_number, trajectory_number)].append(fn)\n",
        "        return filename_groupings\n",
        "    \n",
        "    def _get_initial_filename_dataframe(self, filename_groupings):\n",
        "        '''\n",
        "        Given the filename groupings from the above, create a dataframe\n",
        "        of the schema [trajectory, index, image1, image2]\n",
        "        '''\n",
        "        filename_df = pd.DataFrame(columns=['trajectory', 'index', 'img1', 'img2'])\n",
        "        for k,v in filename_groupings.items():\n",
        "            (index, traj) = k\n",
        "            img1, img2 = None, None\n",
        "            v.sort()\n",
        "            if len(v) == 2:\n",
        "                img1, img2 = v[0], v[1]\n",
        "            elif len(v) == 1:\n",
        "                img1 = v[0]\n",
        "            filename_df = filename_df.append({\n",
        "                'trajectory': traj,\n",
        "                'index': index,\n",
        "                'img1': img1,\n",
        "                'img2': img2\n",
        "            }, ignore_index=True)\n",
        "        filename_df['trajectory'] = filename_df['trajectory'].astype('str')\n",
        "        filename_df['index'] = filename_df['index'].astype('int')\n",
        "        filename_df = filename_df.dropna(subset=['img1','img2']) # Drop if any of our images is None.\n",
        "        return filename_df\n",
        "    \n",
        "    def _get_filename_dataframe_with_steps(self, filename_df):\n",
        "        '''\n",
        "        Given the filename df from the above, loop through it and get \n",
        "        the (t,t) and (t, t+1) pairings.\n",
        "        '''\n",
        "        schema = [\n",
        "            'trajectory',\n",
        "            'index',\n",
        "            'img1_t0',\n",
        "            'img2_t0',\n",
        "            'img1_t1',\n",
        "            'img2_t1']\n",
        "        timestep_df = pd.DataFrame(columns=schema)\n",
        "        num_rows, _ = filename_df.shape\n",
        "        for i in range(num_rows): # blah blah yeah i know i'm not vectorizing. \n",
        "            ith_row = filename_df.iloc[i]\n",
        "            row_dict = {\n",
        "                'trajectory': ith_row['trajectory'],\n",
        "                'index': ith_row['index'],\n",
        "                'img1_t0': ith_row['img1'],\n",
        "                'img2_t0': ith_row['img2']\n",
        "            }\n",
        "            # First, construct the stationary row\n",
        "            stationary_row = row_dict.copy()\n",
        "            stationary_row['img1_t1'] = ith_row['img1']\n",
        "            stationary_row['img2_t1'] = ith_row['img2']\n",
        "            timestep_df = timestep_df.append(stationary_row, ignore_index=True)\n",
        "            # Then, construct the t+1th row IF it exists\n",
        "            next_timestep_row = self._construct_next_timestep_row(\n",
        "                row_dict, ith_row, filename_df)\n",
        "            timestep_df = timestep_df.append(next_timestep_row, ignore_index=True)\n",
        "        timestep_df['trajectory'] = timestep_df['trajectory'].astype('str')\n",
        "        timestep_df['index'] = timestep_df['index'].astype('int')\n",
        "        return timestep_df\n",
        "\n",
        "    def _construct_next_timestep_row(self, row_dict, ith_row, filename_df):\n",
        "        delta = 4\n",
        "        next_index = ith_row['index'] + delta\n",
        "        mask = (filename_df['index'] == next_index) & (filename_df['trajectory'] == ith_row['trajectory'])\n",
        "        res = filename_df[mask]\n",
        "        num_results = len(res)\n",
        "        if num_results > 1:\n",
        "            print(\"THERE'S MORE THAN ONE RESULT WHEN MAKING THE DATAFRAME\")\n",
        "        if num_results == 1:\n",
        "            next_step_row = row_dict.copy()\n",
        "            next_step_row['img1_t1'] = res['img1'].values[0]\n",
        "            next_step_row['img2_t1'] = res['img2'].values[0]\n",
        "            return next_step_row\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHtv9Wq9nIL3",
        "colab_type": "text"
      },
      "source": [
        "### Model: `siameseCVAE.py` (xcxc To be changed later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1p1k2hTecrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtC1hjdInHm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseCVAE(nn.Module):\n",
        "\tdef __init__(self,batch=4):\n",
        "\t\tsuper().__init__()\n",
        "\t\td = 0.4\n",
        "\t\tself.z_size = 64\n",
        "\t\tself.small = 256\n",
        "\t\tself.hidden = 1024\n",
        "\t\tch_sz = 1\n",
        "\t\tc1 = 64\n",
        "\t\tc2 = 16\n",
        "\t\tlast_conv = 4\n",
        "\t\tself.tensor = (batch,last_conv,150,200)\n",
        "\t\tflat = np.prod(self.tensor)\n",
        "\t\tflat2 = flat*2\n",
        "\n",
        "\t\t# channel_in, c_out, kernel_size, stride, padding\n",
        "\t\tdef convbn(ci,co,ksz,s=1,pz=0):\t\t#ReLu nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef convout(ci,co,ksz,s=1,pz=0):\t#Sigmoid nonlinearity\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(ci,co,ksz,stride=s,padding=pz),\n",
        "\t\t\t\tnn.Sigmoid(),\n",
        "\t\t\t\tnn.BatchNorm2d(co))\n",
        "\t\tdef mlp(in_size,hidden):\n",
        "\t\t\treturn nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tnn.Linear(in_size,hidden),\n",
        "\t\t\t\tnn.ReLU())\n",
        "\n",
        "\t\t#Encoder NN\n",
        "\t\tself.encx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.ency = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(ch_sz,c1,3,1,1),\n",
        "\t\t\t\tconvbn(c1,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,last_conv,3,1,1))\n",
        "\t\tself.m1 = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(flat2,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden, self.small))\n",
        "\t\tself.zmean = nn.Linear(self.small,self.z_size)\n",
        "\t\tself.zlogvar = nn.Linear(self.small,self.z_size)\n",
        "\n",
        "\t\t#Decoder NN\n",
        "\t\tself.expand_z = nn.Linear(self.z_size,self.small)\n",
        "\t\tself.mx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.my = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tmlp(self.small,self.hidden),\n",
        "\t\t\t\tmlp(self.hidden,flat))\n",
        "\t\tself.decx = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\t\tself.decy = nn.Sequential(\n",
        "\t\t\t\tnn.Dropout(d),\n",
        "\t\t\t\tconvbn(last_conv,c2,3,1,1),\n",
        "\t\t\t\tconvbn(c2,c1,3,1,1),\n",
        "\t\t\t\tconvout(c1,ch_sz,3,1,1))\n",
        "\n",
        "\tdef encoder(self, x, y):\n",
        "\t\t# Flatten enc output\n",
        "\t\th_x = self.encx(x).view(-1)\n",
        "\t\th_y = self.ency(y).view(-1)\n",
        "\t\t# Concatenate flat convs\n",
        "\t\th_layer = torch.cat((h_x,h_y))\n",
        "\t\th = self.m1(h_layer)\n",
        "\t\treturn h\n",
        "\n",
        "\tdef bottleneck(self, x):\n",
        "\t\tz_mean = self.zmean(x)\n",
        "\t\tz_logvar = self.zlogvar(x)\n",
        "\t\t#reparam to get z latent sample\n",
        "\t\tstd = torch.exp(0.5*z_logvar)\n",
        "\t\teps = torch.randn_like(std)\n",
        "\t\tz = z_mean + eps*std\n",
        "\t\treturn z, z_mean, z_logvar\n",
        "\n",
        "\tdef decoder(self, z):\n",
        "\t\t#check the nonlinearities of this layer\n",
        "\t\th = self.expand_z(z)\n",
        "\t\t#exand z to each decoder head\n",
        "\t\th_x = self.mx(h)\n",
        "\t\th_y = self.my(h)\n",
        "\t\t#make sure to reshape data correctly and decode\n",
        "\t\tx = self.decx(h_x.view(self.tensor))\n",
        "\t\ty = self.decy(h_x.view(self.tensor))\n",
        "\t\treturn x, y\n",
        "\n",
        "\tdef forward(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\tx_hat, y_hat = self.decoder(z)\n",
        "\t\treturn x_hat, y_hat, z, z_mean, z_logvar\n",
        "\n",
        "\tdef encode_get_z(self, x, y):\n",
        "\t\th = self.encoder(x, y)\n",
        "\t\tz, z_mean, z_logvar = self.bottleneck(h)\n",
        "\t\treturn z, z_mean, z_logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eXmqdvaJMV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _rearrange_channel_last(img, color = False):\n",
        "    _,_,H,W = img.shape\n",
        "    if color == True:\n",
        "        new_img = np.zeros((H,W,3))\n",
        "        for i in range(3):\n",
        "            new_img[:,:,i] = img[0,i,:,:]\n",
        "    else:\n",
        "        new_img = np.zeros((H,W))\n",
        "        new_img[:,:] = img[0,0,:,:]\n",
        "    return new_img\n",
        "\n",
        "def ELBO_loss(xhat, x, yhat, y, mu, logvar):\n",
        "    mseloss = nn.MSELoss(reduction='sum')\n",
        "    MSE_X = mseloss(xhat, x)\n",
        "    MSE_Y = mseloss(yhat, y)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return MSE_X+MSE_Y+KLD, MSE_X, MSE_Y, KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhgG8l-L32i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize((150,200)),\n",
        "        transforms.ToTensor()])\n",
        "batch = 1\n",
        "path = \"/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/data\"\n",
        "dl = DataLoader(CarlaDataset(path, load_as_grayscale=True, transform=transform), batch_size=batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXWrqmrnfEl",
        "colab_type": "text"
      },
      "source": [
        "### Training Script: `run_script.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POg-yHcNm7xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, optimizer, criterion, epochs, batch, exp_name):\n",
        "    model = net.to(device)\n",
        "    total_step = 0\n",
        "    losses = []\n",
        "    kl_loss = []\n",
        "    mseX_loss = []\n",
        "    mseY_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        running_loss = 0.0\n",
        "        kl_running = 0.0\n",
        "        mseX_running = 0.0\n",
        "        mseY_running = 0.0\n",
        "\n",
        "        for i, X in enumerate(dl):\n",
        "            left_image_t = X[0][:, 1, :, :, :] # left/right images of t\n",
        "            right_image_t = X[0][:, 0, :, :, :] # left/right images of t\n",
        "            # img2 = X[1] # left/right of t+1 # xcxc do the same indexing above to get l/r of t+1\n",
        "\n",
        "            left_image_t = (left_image_t).float().to(device)\n",
        "            right_image_t = (right_image_t).float().to(device)\n",
        "\n",
        "            xhat, yhat, z, z_mean, z_logvar = model.forward(left_image_t,right_image_t)\n",
        "            loss, MSE_X, MSE_Y, KLD = criterion(xhat,left_image_t, yhat, right_image_t, z_mean, z_logvar)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_step += 1\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            kl_running += KLD.item()\n",
        "            mseX_running += MSE_X.item()\n",
        "            mseY_running += MSE_Y.item()\n",
        "            total += batch\n",
        "\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
        "            if i == 25:\n",
        "                break\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
        "            chpt_path = '/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/checkpoints/'+exp_name+'.pt'\n",
        "            torch.save(model.state_dict(), chpt_path)\n",
        "\n",
        "        losses.append(running_loss/total)     \n",
        "        kl_loss.append(kl_running/total)\n",
        "        mseX_loss.append(mseX_running/total)\n",
        "        mseY_loss.append(mseY_running/total)  \n",
        "    \n",
        "    ells = {'elbo':losses,\n",
        "            'kl':kl_loss,\n",
        "            'mseX':mseX_loss,\n",
        "            'mseY':mseY_loss}\n",
        "\n",
        "    with open('/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/logs/'+exp_name+'_losses.pickle', 'wb') as f:\n",
        "        pickle.dump(ells, f)\n",
        "\n",
        "    left = []\n",
        "    right = []\n",
        "    recon_left = []\n",
        "    recon_right = []\n",
        "    for i, X in enumerate(dl):\n",
        "        model.eval()\n",
        "        left_image_t = (X[0][:, 1, :, :, :]).float().to(device) # left/right images of t\n",
        "        right_image_t = (X[0][:, 0, :, :, :]).float().to(device) # left/right images of t\n",
        "        ctrl_inputs = X[2]\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(left_image_t,right_image_t)\n",
        "\n",
        "        left_ = left_image_t.cpu().squeeze().numpy()\n",
        "        right_ = right_image_t.cpu().squeeze().numpy()\n",
        "        xhat_ = xhat.cpu().detach().squeeze().numpy()\n",
        "        yhat_ = yhat.cpu().detach().squeeze().numpy()\n",
        "\n",
        "        left.append(left_)\n",
        "        right.append(right_)\n",
        "        recon_left.append(xhat_)\n",
        "        recon_right.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "    left = np.asarray(left)\n",
        "    right = np.asarray(right)\n",
        "    recon_left = np.asarray(recon_left)\n",
        "    recon_right = np.asarray(recon_right)\n",
        "\n",
        "    plt.plot(losses, label='ELBO')\n",
        "    plt.plot(kl_loss, label='KL')\n",
        "    plt.plot(mseX_loss, label='MSE')\n",
        "    plt.plot(mseY_loss, label='MSE')\n",
        "    plt.title('Train loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[0], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[0], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[0], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[0], cmap = 'gray')\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[30], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[30], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[30], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[30], cmap = 'gray')\n",
        "\n",
        "\n",
        "#Run from here\n",
        "exp_name = 'siamese_test'\n",
        "model = siameseCVAE(batch=batch)\n",
        "# checkpoint = torch.load('/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/checkpoints/siamese_chpt.pt')\n",
        "# model.load_state_dict(checkpoint) \n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "train(model, optimizer, criterion, epochs, batch, exp_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2WyBxnnGGj1",
        "colab_type": "text"
      },
      "source": [
        "Evaluate Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6F89kRKhtX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, optimizer, criterion, epochs):\n",
        "    model = net.to(device)    \n",
        "    left = []\n",
        "    right = []\n",
        "    recon_left = []\n",
        "    recon_right = []\n",
        "    for i, X in enumerate(dl):\n",
        "        model.eval()\n",
        "        left_image_t = (X[0][:, 1, :, :, :]).float().to(device) # left/right images of t\n",
        "        right_image_t = (X[0][:, 0, :, :, :]).float().to(device) # left/right images of t\n",
        "        ctrl_inputs = X[2]\n",
        "\n",
        "        #Forward Pass\n",
        "        xhat, yhat, z, z_mean, z_stdev = model.forward(left_image_t,right_image_t)\n",
        "\n",
        "        color = False\n",
        "        left_ = _rearrange_channel_last(left_image_t.cpu(), color)\n",
        "        right_ = _rearrange_channel_last(right_image_t.cpu(), color)\n",
        "        xhat_ = _rearrange_channel_last(xhat.cpu().detach().numpy(), color)\n",
        "        yhat_ = _rearrange_channel_last(yhat.cpu().detach().numpy(), color)\n",
        "        left.append(left_)\n",
        "        right.append(right_)\n",
        "        recon_left.append(xhat_)\n",
        "        recon_right.append(yhat_)\n",
        "        if i == 40:\n",
        "            break\n",
        "    left = np.asarray(left)\n",
        "    right = np.asarray(right)\n",
        "    recon_left = np.asarray(recon_left)\n",
        "    recon_right = np.asarray(recon_right)\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[0], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[0], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[0], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[0], cmap = 'gray')\n",
        "    plt.figure()\n",
        "    plt.subplot(221)\n",
        "    plt.imshow(left[20], cmap = 'gray')\n",
        "    plt.subplot(222)\n",
        "    plt.imshow(right[20], cmap = 'gray')\n",
        "    plt.subplot(223)\n",
        "    plt.imshow(recon_left[20], cmap = 'gray')\n",
        "    plt.subplot(224)\n",
        "    plt.imshow(recon_right[20], cmap = 'gray')\n",
        "\n",
        "\n",
        "#Run from here\n",
        "model = siameseCVAE(batch=batch)\n",
        "checkpoint = torch.load('/content/drive/My Drive/Colab_Notebooks/ESE546_DL_Colab/project/checkpoints/siamese_chpt.pt')\n",
        "model.load_state_dict(checkpoint) \n",
        "\n",
        "epochs = 1\n",
        "criterion = ELBO_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
        "\n",
        "train(model, optimizer, criterion, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNHSy7MiT2kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}